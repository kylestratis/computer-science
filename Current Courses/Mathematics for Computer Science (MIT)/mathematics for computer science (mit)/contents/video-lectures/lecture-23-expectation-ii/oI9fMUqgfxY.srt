1
00:00:00,000 --> 00:00:00,500


2
00:00:00,500 --> 00:00:02,820
The following content is
provided under a Creative

3
00:00:02,820 --> 00:00:04,340
Commons license.

4
00:00:04,340 --> 00:00:06,670
Your support will help
MIT OpenCourseWare

5
00:00:06,670 --> 00:00:11,040
continue to offer high quality
educational resources for free.

6
00:00:11,040 --> 00:00:13,650
To make a donation or
view additional materials

7
00:00:13,650 --> 00:00:17,556
from hundreds of MIT courses,
visit MIT OpenCourseWare

8
00:00:17,556 --> 00:00:18,181
at ocw.mit.edu.

9
00:00:18,181 --> 00:00:23,447


10
00:00:23,447 --> 00:00:25,280
PROFESSOR: Last time
we defined the expected

11
00:00:25,280 --> 00:00:27,030
value of a random variable.

12
00:00:27,030 --> 00:00:29,570
And we talked about a lot of
ways it could be computed.

13
00:00:29,570 --> 00:00:33,090
We proved all sorts of
equivalent definitions.

14
00:00:33,090 --> 00:00:35,730
Today, we're going to keep
talking about expectation.

15
00:00:35,730 --> 00:00:38,970
And we're going to start
with an example that

16
00:00:38,970 --> 00:00:42,030
talks about the expected
number of events

17
00:00:42,030 --> 00:00:43,770
that you expect to have occur.

18
00:00:43,770 --> 00:00:45,200
And it's a
generalization of what

19
00:00:45,200 --> 00:00:50,946
we did with Chinese appetizer
and hat check from last time.

20
00:00:50,946 --> 00:00:52,910
We're going to call
this theorem 1.

21
00:00:52,910 --> 00:00:55,600


22
00:00:55,600 --> 00:01:06,360
If you have a
probability space, s,

23
00:01:06,360 --> 00:01:10,860
and you've got a
collection of n events,

24
00:01:10,860 --> 00:01:20,310
let's call them A1 through
A n, and these are just

25
00:01:20,310 --> 00:01:31,750
subsets of s, then the expected
number of events to occur,

26
00:01:31,750 --> 00:01:47,375
of these events, is simply
the sum of i equals 1 to n

27
00:01:47,375 --> 00:01:52,610
of the probability of
the i-th event occurring.

28
00:01:52,610 --> 00:01:54,380
So you just sum up
the probabilities

29
00:01:54,380 --> 00:01:56,250
that the events occur.

30
00:01:56,250 --> 00:01:58,400
And that tells you
the expected number

31
00:01:58,400 --> 00:02:00,185
of events that will occur.

32
00:02:00,185 --> 00:02:03,320
So a very simple formula.

33
00:02:03,320 --> 00:02:06,730
So for example, A i
might be the event

34
00:02:06,730 --> 00:02:10,829
if the i-th man gets the
right hat back from last time.

35
00:02:10,829 --> 00:02:13,570
Or it could be the event
if the i-th person gets

36
00:02:13,570 --> 00:02:16,140
the right appetizer back
at the Chinese restaurant

37
00:02:16,140 --> 00:02:20,320
after we spin the
wheel in the center.

38
00:02:20,320 --> 00:02:21,890
So we're going to prove this.

39
00:02:21,890 --> 00:02:24,677
And the proof is very similar
to what we did last time when

40
00:02:24,677 --> 00:02:26,510
we figured out the
expected number of people

41
00:02:26,510 --> 00:02:28,350
to get the right hat back.

42
00:02:28,350 --> 00:02:31,810
In particular, we're going
to start by setting up

43
00:02:31,810 --> 00:02:36,160
an indicator variable, T sub
i, that tells us whether or not

44
00:02:36,160 --> 00:02:38,610
the i-th event, A sub i occurs.

45
00:02:38,610 --> 00:02:42,710


46
00:02:42,710 --> 00:02:50,400
So we define T sub i-- and it's
a function of a sample point--

47
00:02:50,400 --> 00:02:55,650
to be 1 if the sample
point is in the i-th event,

48
00:02:55,650 --> 00:02:59,310
meaning the i-th event
occurs, and 0 otherwise.

49
00:02:59,310 --> 00:03:03,050


50
00:03:03,050 --> 00:03:05,220
And this is just
another way of saying

51
00:03:05,220 --> 00:03:13,910
that T sub i is 1 if and only
if A sub i happens or occurs.

52
00:03:13,910 --> 00:03:18,810


53
00:03:18,810 --> 00:03:21,970
Now what we care about is the
number of events that occur.

54
00:03:21,970 --> 00:03:25,550
And we get that just by
summing up the T sub i.

55
00:03:25,550 --> 00:03:33,805
So we'll let T be
T1 plus T2 plus T n.

56
00:03:33,805 --> 00:03:36,220
And that'll count because
we'll get a 1 every time

57
00:03:36,220 --> 00:03:37,060
an event occurs.

58
00:03:37,060 --> 00:03:39,260
By adding those up,
we'll get the number

59
00:03:39,260 --> 00:03:42,570
of events that occur.

60
00:03:42,570 --> 00:03:43,070
All right.

61
00:03:43,070 --> 00:03:46,210
Now we care about
the expected value

62
00:03:46,210 --> 00:03:49,760
of T, the expected number
of events to occur.

63
00:03:49,760 --> 00:03:53,870
And I claim that's just
the sum i equals 1 to n

64
00:03:53,870 --> 00:03:57,200
of the expected value of T i.

65
00:03:57,200 --> 00:03:58,110
Why is that true?

66
00:03:58,110 --> 00:04:01,540


67
00:04:01,540 --> 00:04:06,740
Why is the expected value of T
the sum of the expected values

68
00:04:06,740 --> 00:04:09,440
of the T sub i?

69
00:04:09,440 --> 00:04:11,610
Linearity of expectations.

70
00:04:11,610 --> 00:04:15,910
Now did we need the T sub i's to
be independent events for that?

71
00:04:15,910 --> 00:04:16,970
No.

72
00:04:16,970 --> 00:04:17,884
OK, very good.

73
00:04:17,884 --> 00:04:20,480


74
00:04:20,480 --> 00:04:25,180
Now the expected value of T
i is really easy to evaluate.

75
00:04:25,180 --> 00:04:27,220
It's just a 0, 1 variable.

76
00:04:27,220 --> 00:04:33,130
So it's just the
probability that T i is 1

77
00:04:33,130 --> 00:04:36,800
because it's 1 times this plus
0 times the probability of 0,

78
00:04:36,800 --> 00:04:39,470
and that cancels out.

79
00:04:39,470 --> 00:04:41,440
And the event that
T i equals 1 is just

80
00:04:41,440 --> 00:04:53,530
the situation where the i-th
event occurs because T i equals

81
00:04:53,530 --> 00:04:56,090
1 is the case that A i occurs.

82
00:04:56,090 --> 00:04:58,770
That's what it is.

83
00:04:58,770 --> 00:05:01,770
So we've shown that the expected
number of events to occur

84
00:05:01,770 --> 00:05:04,070
is simply the sum
of the probabilities

85
00:05:04,070 --> 00:05:05,620
that the events occur.

86
00:05:05,620 --> 00:05:10,630
So a very simple
formula, very handy.

87
00:05:10,630 --> 00:05:13,630
And you don't need
independence for that.

88
00:05:13,630 --> 00:05:18,020
Any questions about that?

89
00:05:18,020 --> 00:05:20,210
We're going to use that
theorem a lot today.

90
00:05:20,210 --> 00:05:26,445
As a simple example, suppose
we flip n fair coins.

91
00:05:26,445 --> 00:05:30,110


92
00:05:30,110 --> 00:05:35,640
And we let A i be the event
that the i-th coin is heads.

93
00:05:35,640 --> 00:05:40,560


94
00:05:40,560 --> 00:05:43,590
And suppose we want to know
the expected number of heads

95
00:05:43,590 --> 00:05:46,640
in the n flips.

96
00:05:46,640 --> 00:05:49,530
Well, we can use this theorem.

97
00:05:49,530 --> 00:05:51,954
The expected number
of heads is just

98
00:05:51,954 --> 00:05:53,620
going to be the sum
of the probabilities

99
00:05:53,620 --> 00:05:55,930
that each coin is a heads.

100
00:05:55,930 --> 00:05:57,960
So let's do that.

101
00:05:57,960 --> 00:05:59,300
T is the number of heads.

102
00:05:59,300 --> 00:06:02,880


103
00:06:02,880 --> 00:06:05,460
We want to know the
expected value of T.

104
00:06:05,460 --> 00:06:07,810
And from theorem
one, that's just

105
00:06:07,810 --> 00:06:11,070
the probability the first coin
is heads plus the probability

106
00:06:11,070 --> 00:06:13,700
the second coin is heads.

107
00:06:13,700 --> 00:06:16,070
And the same out to the
probability the n-th coin

108
00:06:16,070 --> 00:06:18,700
is heads.

109
00:06:18,700 --> 00:06:20,690
What's the probability
the first coin is heads?

110
00:06:20,690 --> 00:06:23,750


111
00:06:23,750 --> 00:06:25,620
And 1/2.

112
00:06:25,620 --> 00:06:29,614
The probability the second
coin is heads is a 1/2.

113
00:06:29,614 --> 00:06:31,530
The probability the last
coin is heads is 1/2.

114
00:06:31,530 --> 00:06:34,730


115
00:06:34,730 --> 00:06:38,740
And so the expected number of
heads-- we add up 1/2 n times--

116
00:06:38,740 --> 00:06:41,798
is just n/2.

117
00:06:41,798 --> 00:06:43,470
Of course, you all knew that.

118
00:06:43,470 --> 00:06:45,800
If you flip n fair coins,
the expected number of heads

119
00:06:45,800 --> 00:06:46,900
is half of them.

120
00:06:46,900 --> 00:06:50,770
But that's a very
simple way to prove it.

121
00:06:50,770 --> 00:06:53,290
Did we need the coin
tosses to be mutually

122
00:06:53,290 --> 00:06:55,720
independent to conclude that?

123
00:06:55,720 --> 00:06:58,290


124
00:06:58,290 --> 00:06:59,050
No.

125
00:06:59,050 --> 00:07:03,140
I could've glued them
together in some weird way.

126
00:07:03,140 --> 00:07:06,740
In fact, I could have glued
some face up and some face down

127
00:07:06,740 --> 00:07:08,920
and done weird
things, and you still

128
00:07:08,920 --> 00:07:12,060
expect n/2 heads even if
they were glued together

129
00:07:12,060 --> 00:07:13,480
in strange ways.

130
00:07:13,480 --> 00:07:15,490
Because I don't
need independence

131
00:07:15,490 --> 00:07:17,610
for linearity of
expectation to prove this.

132
00:07:17,610 --> 00:07:21,080


133
00:07:21,080 --> 00:07:24,242
Now that's the easy
way to evaluate

134
00:07:24,242 --> 00:07:25,450
the expected number of heads.

135
00:07:25,450 --> 00:07:27,920
There is a hard way to do it.

136
00:07:27,920 --> 00:07:29,790
Let me set that up.

137
00:07:29,790 --> 00:07:31,630
We could start from
the definition,

138
00:07:31,630 --> 00:07:38,040
a different definition, namely,
that the expected value of T

139
00:07:38,040 --> 00:07:43,140
is the sum from i equals 0 to n.

140
00:07:43,140 --> 00:07:48,300
i times the probability
that you have i heads.

141
00:07:48,300 --> 00:07:50,670
This would be a
natural way to compute

142
00:07:50,670 --> 00:07:52,260
the expected number of heads.

143
00:07:52,260 --> 00:07:54,050
You add up the
case where there's

144
00:07:54,050 --> 00:07:56,390
zero heads times the
probability of 0,

145
00:07:56,390 --> 00:07:58,600
1 times the probability
of one head, 2 times

146
00:07:58,600 --> 00:08:00,096
probably two heads,
and so forth.

147
00:08:00,096 --> 00:08:02,220
That's one of the first
definitions of expectation.

148
00:08:02,220 --> 00:08:04,820


149
00:08:04,820 --> 00:08:06,555
So let's keep trying to do this.

150
00:08:06,555 --> 00:08:09,410


151
00:08:09,410 --> 00:08:12,402
What is the probability
of getting i heads?

152
00:08:12,402 --> 00:08:13,860
And now I'm going
to have to assume

153
00:08:13,860 --> 00:08:15,530
mutual independence actually.

154
00:08:15,530 --> 00:08:18,360
Now I'm going to need
mutual independence.

155
00:08:18,360 --> 00:08:20,439
So already, this
method isn't as good

156
00:08:20,439 --> 00:08:21,980
because I had to
make that assumption

157
00:08:21,980 --> 00:08:24,524
to answer this question.

158
00:08:24,524 --> 00:08:25,940
If you don't make
that assumption,

159
00:08:25,940 --> 00:08:27,420
you can't answer that question.

160
00:08:27,420 --> 00:08:31,040
What's the probability of
getting i heads out of n.

161
00:08:31,040 --> 00:08:32,745
Yeah?

162
00:08:32,745 --> 00:08:36,700
AUDIENCE: s to the n-th
power times n [INAUDIBLE] i.

163
00:08:36,700 --> 00:08:40,789
PROFESSOR: Yes, because if
you look at the sample space,

164
00:08:40,789 --> 00:08:45,110
there are 2 to the n sample
points all equally likely.

165
00:08:45,110 --> 00:08:47,310
They're all probability
2 the minus n.

166
00:08:47,310 --> 00:08:52,590
And there's n choose i of
them that have i heads.

167
00:08:52,590 --> 00:08:57,570
And now you'd have to
evaluate that sum which

168
00:08:57,570 --> 00:08:59,520
is sort of a pain.

169
00:08:59,520 --> 00:09:03,320
That one won't come
to mind readily.

170
00:09:03,320 --> 00:09:06,940
So you might say I reached
sort of a dead end here.

171
00:09:06,940 --> 00:09:09,910
But in fact, the answer
is easy to use, easy

172
00:09:09,910 --> 00:09:13,330
to get using this method.

173
00:09:13,330 --> 00:09:16,580
In fact, we've actually
proved an identity here

174
00:09:16,580 --> 00:09:18,440
because we know
the answer is n/2.

175
00:09:18,440 --> 00:09:23,360
We've just proved that
this messy thing is n/2.

176
00:09:23,360 --> 00:09:26,400


177
00:09:26,400 --> 00:09:28,930
In fact, you can multiply
by 2 to the n here.

178
00:09:28,930 --> 00:09:32,840
We have proved, using
probability theory and theorem

179
00:09:32,840 --> 00:09:39,660
1 over there, the sum of
i n choose i equals n 2

180
00:09:39,660 --> 00:09:43,770
to the n minus 1.

181
00:09:43,770 --> 00:09:46,370
Just multiply by 2 to
the n on each side.

182
00:09:46,370 --> 00:09:48,700
So we've given a
probability based

183
00:09:48,700 --> 00:09:55,040
proof of this identity which is
sort of hard to do otherwise,

184
00:09:55,040 --> 00:09:56,630
could be harder to do.

185
00:09:56,630 --> 00:09:59,640
Any questions about that?

186
00:09:59,640 --> 00:10:03,570
So again, if it comes time for
a homework problem or a test

187
00:10:03,570 --> 00:10:06,950
problem, if it
naturally divides up

188
00:10:06,950 --> 00:10:11,030
in this way where you can
take a random variable when

189
00:10:11,030 --> 00:10:13,750
you got a computer's expectation
to make it a sum of indicator

190
00:10:13,750 --> 00:10:17,760
variables, if that is a natural
thing to do, do it that way.

191
00:10:17,760 --> 00:10:20,370
Because it's so much
easier than trying

192
00:10:20,370 --> 00:10:22,770
to go from the
definition because you

193
00:10:22,770 --> 00:10:24,430
might encounter
nasty things like

194
00:10:24,430 --> 00:10:26,290
that that you got to evaluate.

195
00:10:26,290 --> 00:10:32,150


196
00:10:32,150 --> 00:10:33,840
So in this case,
we flipped n coins.

197
00:10:33,840 --> 00:10:36,050
We expect n/2 heads.

198
00:10:36,050 --> 00:10:39,650
In the hat check, in
Chinese appetizer problems--

199
00:10:39,650 --> 00:10:42,620
we had n hats or n
appetizers-- we expected

200
00:10:42,620 --> 00:10:46,490
to get one back to the right
person-- so a smaller expected

201
00:10:46,490 --> 00:10:48,150
value.

202
00:10:48,150 --> 00:10:51,890
For some problems, the
expected value is even less.

203
00:10:51,890 --> 00:10:54,550
The expected number of events
to occur is less than 1.

204
00:10:54,550 --> 00:10:57,130
In fact, it might
be much less than 1.

205
00:10:57,130 --> 00:11:01,980
Now in those cases it turns
out that the expected value

206
00:11:01,980 --> 00:11:07,710
is an upper bound
on the probability

207
00:11:07,710 --> 00:11:10,280
that one or more events occur.

208
00:11:10,280 --> 00:11:11,910
We're going to state
this as theorem 2.

209
00:11:11,910 --> 00:11:18,090


210
00:11:18,090 --> 00:11:22,190
The probability that at
least one event occurs

211
00:11:22,190 --> 00:11:25,570
is always upper bounded by
the expected number of events

212
00:11:25,570 --> 00:11:27,450
to occur.

213
00:11:27,450 --> 00:11:29,090
Now this theorem
is pretty useless

214
00:11:29,090 --> 00:11:32,220
if the expected number of
events to occur is bigger than 1

215
00:11:32,220 --> 00:11:35,230
because all probabilities
are at most 1.

216
00:11:35,230 --> 00:11:37,190
But if the expected
number of events to occur

217
00:11:37,190 --> 00:11:40,080
is small, something
much less than 1,

218
00:11:40,080 --> 00:11:43,100
this is a pretty useful bound.

219
00:11:43,100 --> 00:11:44,025
So let's prove that.

220
00:11:44,025 --> 00:11:47,380


221
00:11:47,380 --> 00:11:50,710
The expected value of
T-- and in this case

222
00:11:50,710 --> 00:11:54,200
we'll use one of the definitions
we have of expected value,

223
00:11:54,200 --> 00:11:56,710
name of the one
where you sum from i

224
00:11:56,710 --> 00:12:01,056
equals 1 to infinity
of the probability T

225
00:12:01,056 --> 00:12:04,210
is greater than or equal to i.

226
00:12:04,210 --> 00:12:08,951
Now what did we have to know
about T to use that definition?

227
00:12:08,951 --> 00:12:11,240
That doesn't work for
all random variables

228
00:12:11,240 --> 00:12:19,650
T. What condition do I have on
T to be able to use this one?

229
00:12:19,650 --> 00:12:20,770
Anybody remember?

230
00:12:20,770 --> 00:12:21,289
Yeah.

231
00:12:21,289 --> 00:12:23,330
AUDIENCE: Must be defined
on the natural numbers?

232
00:12:23,330 --> 00:12:25,371
PROFESSOR: T must defined
on the natural numbers.

233
00:12:25,371 --> 00:12:28,890
If it is, I can use this
very simple definition.

234
00:12:28,890 --> 00:12:31,260
And is T defined on the
natural numbers here?

235
00:12:31,260 --> 00:12:34,560
Is the range of T
natural numbers?

236
00:12:34,560 --> 00:12:37,920
Well, I'm counting the number
of events that occurred.

237
00:12:37,920 --> 00:12:39,575
Could be 0, 1, 2, 3, 4.

238
00:12:39,575 --> 00:12:40,700
Has to be a natural number.

239
00:12:40,700 --> 00:12:42,240
So it's OK.

240
00:12:42,240 --> 00:12:45,300
So I can use this definition.

241
00:12:45,300 --> 00:12:48,860
Now this is summing up
probability T is at least 1

242
00:12:48,860 --> 00:12:51,680
plus probability T is
at least 2 and so forth.

243
00:12:51,680 --> 00:12:53,960
I'm just going to
use the first term.

244
00:12:53,960 --> 00:12:56,425
This is at least the
size of the first term

245
00:12:56,425 --> 00:12:58,050
because probabilities
are non-negative.

246
00:12:58,050 --> 00:13:00,349


247
00:13:00,349 --> 00:13:02,890
So I'm just going to throw away
all the terms after the first

248
00:13:02,890 --> 00:13:05,400
and conclude that this is
at least the probability T

249
00:13:05,400 --> 00:13:07,000
is bigger than or equal to 1.

250
00:13:07,000 --> 00:13:08,882
And I'm done.

251
00:13:08,882 --> 00:13:10,090
I just look at it in reverse.

252
00:13:10,090 --> 00:13:12,680
The probability of at
least one event occurring

253
00:13:12,680 --> 00:13:17,480
is at most the expected value.

254
00:13:17,480 --> 00:13:18,850
Very simple.

255
00:13:18,850 --> 00:13:20,620
There's a very quick
corollary here.

256
00:13:20,620 --> 00:13:24,330


257
00:13:24,330 --> 00:13:26,140
The probability
at least one event

258
00:13:26,140 --> 00:13:31,045
occurs is at most the sum of
the probabilities of the events.

259
00:13:31,045 --> 00:13:34,870


260
00:13:34,870 --> 00:13:39,260
And the proof there is
just plugging in theorem 1.

261
00:13:39,260 --> 00:13:43,920
Because the expected value is
the sum of the probabilities.

262
00:13:43,920 --> 00:13:48,460
So we just plug-in theorem
1 for the expected value

263
00:13:48,460 --> 00:13:49,710
because it's just that.

264
00:13:49,710 --> 00:13:53,930


265
00:13:53,930 --> 00:13:57,900
Any questions about the proof?

266
00:13:57,900 --> 00:13:59,670
Very simple.

267
00:13:59,670 --> 00:14:03,530
Now this theorem is very
useful in situations

268
00:14:03,530 --> 00:14:05,100
where you're trying
to upper bound

269
00:14:05,100 --> 00:14:08,400
the probability of some kind
of disaster or something

270
00:14:08,400 --> 00:14:10,160
bad happening.

271
00:14:10,160 --> 00:14:12,210
For example, suppose
you want to compute

272
00:14:12,210 --> 00:14:16,570
the probability that a
nuclear plant melts down.

273
00:14:16,570 --> 00:14:19,405
Now actually, the
government does this.

274
00:14:19,405 --> 00:14:20,780
They got to figure
this thing out

275
00:14:20,780 --> 00:14:22,488
because if it's a high
probability, well,

276
00:14:22,488 --> 00:14:24,810
we're not going to allow
anybody to build them.

277
00:14:24,810 --> 00:14:29,250
And the way they do it is they
convene a panel of experts.

278
00:14:29,250 --> 00:14:32,160
They get some people from
various good universities

279
00:14:32,160 --> 00:14:33,950
and they bring them
down to Washington.

280
00:14:33,950 --> 00:14:35,940
And they have them
figure out every way

281
00:14:35,940 --> 00:14:39,450
they can think of that
a meltdown could occur,

282
00:14:39,450 --> 00:14:42,800
every possible event that
would lead to a meltdown.

283
00:14:42,800 --> 00:14:46,470
And then they'd have them
figure out the probability

284
00:14:46,470 --> 00:14:48,600
for each one of those events.

285
00:14:48,600 --> 00:14:51,240
For example, A1
could be the event

286
00:14:51,240 --> 00:14:56,180
that the operator goes
crazy and makes it meltdown.

287
00:14:56,180 --> 00:15:00,150
A2 could be the event that an
earthquake hits and the cooling

288
00:15:00,150 --> 00:15:04,340
pipes are ruptured, and
then you got a meltdown.

289
00:15:04,340 --> 00:15:07,800
A3 is the event that terrorists
shoot their way in and cause

290
00:15:07,800 --> 00:15:09,577
a meltdown.

291
00:15:09,577 --> 00:15:11,410
So you've got a lot of
possibilities for how

292
00:15:11,410 --> 00:15:13,730
the thing can melt down.

293
00:15:13,730 --> 00:15:16,000
And then they compute
the probabilities.

294
00:15:16,000 --> 00:15:21,260
And then they add them up
just using this result.

295
00:15:21,260 --> 00:15:23,120
And they say, well,
the probability

296
00:15:23,120 --> 00:15:27,510
that a meltdown-causing
event or one or more occurs

297
00:15:27,510 --> 00:15:29,270
is at most this small number.

298
00:15:29,270 --> 00:15:31,510
And hopefully it's small.

299
00:15:31,510 --> 00:15:37,530
So for example, suppose there's
100 ways that a meltdown could

300
00:15:37,530 --> 00:15:40,730
occur, 100 things that
could cause a meltdown.

301
00:15:40,730 --> 00:15:45,350
And each one happens with
probability one in a million.

302
00:15:45,350 --> 00:15:48,710
What can you say
about the probability

303
00:15:48,710 --> 00:15:49,690
that a meltdown occurs?

304
00:15:49,690 --> 00:15:53,510


305
00:15:53,510 --> 00:15:55,820
You got a hundred ways
it could happen only.

306
00:15:55,820 --> 00:15:58,902
Each is a one in
a million chance.

307
00:15:58,902 --> 00:16:00,610
What's the probability
a meltdown occurs?

308
00:16:00,610 --> 00:16:03,370


309
00:16:03,370 --> 00:16:07,940
1 in 10,000 because you're
adding up one in a million

310
00:16:07,940 --> 00:16:08,940
100 times.

311
00:16:08,940 --> 00:16:10,000
n is 100.

312
00:16:10,000 --> 00:16:12,300
Each of these is
one in a million.

313
00:16:12,300 --> 00:16:13,630
So you get 100 over a million.

314
00:16:13,630 --> 00:16:14,880
There's 1 in 10,000.

315
00:16:14,880 --> 00:16:16,570
And so then they
publish a report that

316
00:16:16,570 --> 00:16:20,500
says the chance of this reactor
melting down is 1 in 10,000.

317
00:16:20,500 --> 00:16:24,969
Now what if I've
got 100 reactors?

318
00:16:24,969 --> 00:16:27,260
What's the chance that at
least one of them melts down?

319
00:16:27,260 --> 00:16:30,990


320
00:16:30,990 --> 00:16:35,020
1 in 100 because I got 100
over 10,000-- same theorem.

321
00:16:35,020 --> 00:16:38,065
So there's a 1 in 100 chance
something melts down somewhere,

322
00:16:38,065 --> 00:16:40,657
at most.

323
00:16:40,657 --> 00:16:42,490
Hopefully, the numbers
are better than that.

324
00:16:42,490 --> 00:16:45,030


325
00:16:45,030 --> 00:16:47,870
Same thing if you bought
100 lottery tickets, each

326
00:16:47,870 --> 00:16:50,270
a one in a million
chance, you got a 1

327
00:16:50,270 --> 00:16:54,780
in 10,000 chance of
winning, at most.

328
00:16:54,780 --> 00:16:59,980
So simple fact but powerful
and used a lot in practice.

329
00:16:59,980 --> 00:17:03,080
And this is sort of
the good case when

330
00:17:03,080 --> 00:17:07,010
the expected number of
events that are bad to happen

331
00:17:07,010 --> 00:17:11,569
is small, like a
lot less than 1.

332
00:17:11,569 --> 00:17:15,760
But what if the expected number
of events to happen is big.

333
00:17:15,760 --> 00:17:18,819
Say it's 10.

334
00:17:18,819 --> 00:17:21,020
Say this government
panel gets together

335
00:17:21,020 --> 00:17:23,030
and they add up all
the probabilities

336
00:17:23,030 --> 00:17:25,530
and it comes out to be 10.

337
00:17:25,530 --> 00:17:29,260
Well, it doesn't sound so
good if that's the case.

338
00:17:29,260 --> 00:17:30,880
But is it necessarily bad?

339
00:17:30,880 --> 00:17:34,000
Does it necessarily
mean that you're

340
00:17:34,000 --> 00:17:35,160
going to have a meltdown.

341
00:17:35,160 --> 00:17:36,810
So for example,
let's say there's

342
00:17:36,810 --> 00:17:39,590
1,000 ways you could melt down.

343
00:17:39,590 --> 00:17:43,350
And let's say that the
probability of each one

344
00:17:43,350 --> 00:17:46,860
is 1 in 100.

345
00:17:46,860 --> 00:17:49,710
So the expected number of
things that could happen

346
00:17:49,710 --> 00:17:53,400
to cause a meltdown is 10.

347
00:17:53,400 --> 00:17:55,120
Am I guaranteed we're
going to melt down?

348
00:17:55,120 --> 00:17:58,590


349
00:17:58,590 --> 00:17:59,710
No.

350
00:17:59,710 --> 00:18:01,680
Can anybody think
of a way where it's

351
00:18:01,680 --> 00:18:04,720
unlikely we're
going to melt down

352
00:18:04,720 --> 00:18:08,280
but respect these values
here, hypothetically?

353
00:18:08,280 --> 00:18:12,282


354
00:18:12,282 --> 00:18:13,740
Is there any chance
that it's still

355
00:18:13,740 --> 00:18:14,906
unlikely to have a meltdown?

356
00:18:14,906 --> 00:18:17,900


357
00:18:17,900 --> 00:18:20,150
We're going to think of a way?

358
00:18:20,150 --> 00:18:20,800
Yeah.

359
00:18:20,800 --> 00:18:22,591
AUDIENCE: They all
happen at the same time.

360
00:18:22,591 --> 00:18:24,800
PROFESSOR: They all
happen at the same time.

361
00:18:24,800 --> 00:18:27,565
Now the examples I gave you--
the terrorists, the earthquake,

362
00:18:27,565 --> 00:18:31,470
and the crazy operator--
put that on the side.

363
00:18:31,470 --> 00:18:34,490
If they all happen together,
when any one happens,

364
00:18:34,490 --> 00:18:37,360
the others have to happen.

365
00:18:37,360 --> 00:18:42,380
So we can express
that as for all ij,

366
00:18:42,380 --> 00:18:44,750
probability of the
i-th event happening

367
00:18:44,750 --> 00:18:51,440
given the j-th event happening
is one, so total dependence.

368
00:18:51,440 --> 00:18:54,060
What's the probability of a
meltdown in that scenario?

369
00:18:54,060 --> 00:18:58,780


370
00:18:58,780 --> 00:19:01,350
What's the probability one of
those meltdown-inducing events

371
00:19:01,350 --> 00:19:01,850
occurs?

372
00:19:01,850 --> 00:19:04,960


373
00:19:04,960 --> 00:19:07,332
They all happen at once.

374
00:19:07,332 --> 00:19:08,320
AUDIENCE: 1 in 100.

375
00:19:08,320 --> 00:19:15,142
PROFESSOR: 1 in 100.

376
00:19:15,142 --> 00:19:17,600
Because it's the same as the
probability of the first event

377
00:19:17,600 --> 00:19:22,180
happening which, by
definition, was 1 in 100.

378
00:19:22,180 --> 00:19:25,400
So it could be that the
probability of a meltdown

379
00:19:25,400 --> 00:19:27,520
is small.

380
00:19:27,520 --> 00:19:29,270
But it might not be as well.

381
00:19:29,270 --> 00:19:31,405
There's no way,
given this, to know.

382
00:19:31,405 --> 00:19:35,030


383
00:19:35,030 --> 00:19:38,940
What if I chain-- in fact,
this is like Chinese appetizer,

384
00:19:38,940 --> 00:19:40,140
right?

385
00:19:40,140 --> 00:19:45,040
If one person gets their
appetizer back, everybody does.

386
00:19:45,040 --> 00:19:47,009
So there are circumstances
where you have

387
00:19:47,009 --> 00:19:48,300
the total dependence like that.

388
00:19:48,300 --> 00:19:51,160


389
00:19:51,160 --> 00:19:54,760
Let's say I change a little bit
and I don't do this scenario.

390
00:19:54,760 --> 00:19:56,760
In fact, say I
tell you the events

391
00:19:56,760 --> 00:20:02,850
are mutually independent,
but you expect 10 to occur.

392
00:20:02,850 --> 00:20:06,210
Do you sleep at night now?

393
00:20:06,210 --> 00:20:08,470
Of course, 1% is still
a pretty high number.

394
00:20:08,470 --> 00:20:12,690
But how many people think that
if they're mutually independent

395
00:20:12,690 --> 00:20:16,630
and you expect 10
that, no matter what,

396
00:20:16,630 --> 00:20:20,931
there's a least a 50%
chance of a meltdown?

397
00:20:20,931 --> 00:20:21,430
Anybody?

398
00:20:21,430 --> 00:20:24,400


399
00:20:24,400 --> 00:20:25,290
OK.

400
00:20:25,290 --> 00:20:32,840
In fact, if you expect 10 and
they're mutually independent,

401
00:20:32,840 --> 00:20:35,260
a meltdown is a
virtual certainty.

402
00:20:35,260 --> 00:20:41,890
The chance you don't melt
down is less than 1 in 22,000.

403
00:20:41,890 --> 00:20:44,270
For sure something
will occur that's bad.

404
00:20:44,270 --> 00:20:50,472
And this is a theorem
that we call Murphy's law.

405
00:20:50,472 --> 00:20:52,555
And Murphy's law, probably
you've all heard of it,

406
00:20:52,555 --> 00:20:53,920
it says-- it's a famous saying.

407
00:20:53,920 --> 00:20:56,679
If something can go
wrong, it will go wrong.

408
00:20:56,679 --> 00:20:58,720
And we're going to see
why that's true, at least,

409
00:20:58,720 --> 00:21:00,900
in our circumstances here.

410
00:21:00,900 --> 00:21:13,795


411
00:21:13,795 --> 00:21:15,170
That's a pretty
powerful theorem.

412
00:21:15,170 --> 00:21:28,870


413
00:21:28,870 --> 00:21:49,380
If you have mutually independent
events A1 through A n, then

414
00:21:49,380 --> 00:21:55,300
the probability that none
of them occur, t equals 0,

415
00:21:55,300 --> 00:22:00,190
is upper bounded by e to the
minus expected number of events

416
00:22:00,190 --> 00:22:02,980
to occur.

417
00:22:02,980 --> 00:22:09,430
So if I expect 10 to occur,
the chance that none do

418
00:22:09,430 --> 00:22:14,660
is upper bounded by e to the
minus 10, which is very small,

419
00:22:14,660 --> 00:22:21,640
which means almost surely one of
the events or more will occur.

420
00:22:21,640 --> 00:22:26,110
And that's bad
news in this case.

421
00:22:26,110 --> 00:22:27,800
So let's prove that.

422
00:22:27,800 --> 00:22:31,900


423
00:22:31,900 --> 00:22:35,690
Well, the probability
that t equals 0

424
00:22:35,690 --> 00:22:39,150
is the same as the probability
that A1 does not occur

425
00:22:39,150 --> 00:22:44,890
and A2 does not occur and all
the way to A n does not occur.

426
00:22:44,890 --> 00:22:47,880


427
00:22:47,880 --> 00:22:50,700
And I claim this
[INAUDIBLE] is the product

428
00:22:50,700 --> 00:22:54,300
of the probabilities
they don't occur.

429
00:22:54,300 --> 00:22:57,110
So I'm taking the
product i equals 1 to n

430
00:22:57,110 --> 00:23:01,240
of the probability that
A i does not occur.

431
00:23:01,240 --> 00:23:02,670
Now why can I make that step?

432
00:23:02,670 --> 00:23:05,850


433
00:23:05,850 --> 00:23:06,350
Yeah.

434
00:23:06,350 --> 00:23:08,270
Independence.

435
00:23:08,270 --> 00:23:11,670
This is the product rule
for independent events.

436
00:23:11,670 --> 00:23:23,840


437
00:23:23,840 --> 00:23:28,560
Now the probability
that A i does not occur

438
00:23:28,560 --> 00:23:31,255
is simply 1 minus the
probability it does occur.

439
00:23:31,255 --> 00:23:35,440


440
00:23:35,440 --> 00:23:39,620
And now I'm going to
use a simple fact, which

441
00:23:39,620 --> 00:23:43,840
is that for any
number x, 1 minus x

442
00:23:43,840 --> 00:23:47,367
is at most e to the minus x.

443
00:23:47,367 --> 00:23:48,700
Just a simple fact from algebra.

444
00:23:48,700 --> 00:23:53,980
So I've got 1 minus-- I'm
going to treat this as the x.

445
00:23:53,980 --> 00:24:03,180
So this is at most e to the
minus probability of A i

446
00:24:03,180 --> 00:24:05,710
using that fact.

447
00:24:05,710 --> 00:24:07,820
And now I'll take the
product and put it

448
00:24:07,820 --> 00:24:09,130
into a sum in the exponent.

449
00:24:09,130 --> 00:24:19,440


450
00:24:19,440 --> 00:24:23,450
And then some of the
probabilities of the events

451
00:24:23,450 --> 00:24:25,190
is just the expected value.

452
00:24:25,190 --> 00:24:28,390
That was theorem 1
that I just erased.

453
00:24:28,390 --> 00:24:31,720
So this is e to the minus
expected number of events

454
00:24:31,720 --> 00:24:34,650
to occur.

455
00:24:34,650 --> 00:24:36,220
So not too hard a proof.

456
00:24:36,220 --> 00:24:38,190
We had to use that fact.

457
00:24:38,190 --> 00:24:41,000
But that gets the
expected number of events

458
00:24:41,000 --> 00:24:44,080
to occur in the exponent.

459
00:24:44,080 --> 00:24:51,010
So a simple corollary
is the case when

460
00:24:51,010 --> 00:24:52,890
we expect 10 events to occur.

461
00:24:52,890 --> 00:25:03,840


462
00:25:03,840 --> 00:25:19,040
So if we expect 10 or more
mutually independent events

463
00:25:19,040 --> 00:25:35,870
to occur, the probability
that no event occurs

464
00:25:35,870 --> 00:25:41,020
is at most e to the minus
10, which is less than 1

465
00:25:41,020 --> 00:25:46,490
over 22,000.

466
00:25:46,490 --> 00:25:50,490
Now there's not even any
dependence on n here.

467
00:25:50,490 --> 00:25:52,740
It had nothing to do with a
number of possible events,

468
00:25:52,740 --> 00:25:55,460
just that if you expect
10 of them to occur,

469
00:25:55,460 --> 00:25:58,910
you're pretty sure
one of them will.

470
00:25:58,910 --> 00:26:04,270
And this explains why you
see weird coincidences.

471
00:26:04,270 --> 00:26:07,880
Or people sometimes see what
they think are miracles.

472
00:26:07,880 --> 00:26:10,720
Because out in the
real world, there's

473
00:26:10,720 --> 00:26:15,360
billions of possible weird
things that could happen.

474
00:26:15,360 --> 00:26:19,450
You just can create all
sorts of crazy possibilities.

475
00:26:19,450 --> 00:26:22,230
And each one might be
one in a billion chance

476
00:26:22,230 --> 00:26:24,800
of actually happening.

477
00:26:24,800 --> 00:26:28,970
But you got billions
that could've.

478
00:26:28,970 --> 00:26:30,710
And if they're all
mutually independent--

479
00:26:30,710 --> 00:26:33,870
because you made up all these
different things-- than you

480
00:26:33,870 --> 00:26:36,940
expect some of them to happen.

481
00:26:36,940 --> 00:26:39,110
And so you should--
in fact, you're

482
00:26:39,110 --> 00:26:42,470
going to know that for sure
some of those weird things

483
00:26:42,470 --> 00:26:43,545
are going to happen.

484
00:26:43,545 --> 00:26:45,720
At least the chance that
no weird thing happens

485
00:26:45,720 --> 00:26:48,500
is 1 in 22,000.

486
00:26:48,500 --> 00:26:50,846
And so this can be why
somebody will go along

487
00:26:50,846 --> 00:26:52,710
and say, oh my goodness.

488
00:26:52,710 --> 00:26:55,650
You won't believe what
happened, a coincidence.

489
00:26:55,650 --> 00:26:57,880
And it's like, wow, the
chance of that happening

490
00:26:57,880 --> 00:26:59,380
was one in a billion.

491
00:26:59,380 --> 00:27:04,046
It must've been a miracle or an
act of God that this happened.

492
00:27:04,046 --> 00:27:06,420
But you're not thinking about
the other 10 billion things

493
00:27:06,420 --> 00:27:07,250
that didn't happen.

494
00:27:07,250 --> 00:27:09,930


495
00:27:09,930 --> 00:27:13,050
So for sure some of those
things are going to happen.

496
00:27:13,050 --> 00:27:17,080
It's not likely that I'm going
to win megabucks next week.

497
00:27:17,080 --> 00:27:19,310
But somebody's going to win.

498
00:27:19,310 --> 00:27:22,860
If enough people play
and it's more than 1

499
00:27:22,860 --> 00:27:24,852
over the probability
that you're going to win,

500
00:27:24,852 --> 00:27:26,310
than it's very
likely somebody will

501
00:27:26,310 --> 00:27:30,010
win if everybody is
guessing randomly.

502
00:27:30,010 --> 00:27:33,110
Any questions about
what we're doing?

503
00:27:33,110 --> 00:27:36,780


504
00:27:36,780 --> 00:27:40,110
So this is amazingly powerful,
this result. In fact,

505
00:27:40,110 --> 00:27:43,040
it's so powerful that
it's going to let me read

506
00:27:43,040 --> 00:27:44,860
somebody's mind in the class.

507
00:27:44,860 --> 00:27:48,980
We're going to do a
little card trick here.

508
00:27:48,980 --> 00:27:51,647
Now the way this
card trick works--

509
00:27:51,647 --> 00:27:52,730
it's a little complicated.

510
00:27:52,730 --> 00:27:54,410
I'm going to need a
volunteer, probably one of you

511
00:27:54,410 --> 00:27:55,390
guys down front.

512
00:27:55,390 --> 00:27:56,480
We'll get you.

513
00:27:56,480 --> 00:28:00,410
And one of your buddies is going
to keep you honest for me here.

514
00:28:00,410 --> 00:28:01,962
I'm going to reveal--
first I'm going

515
00:28:01,962 --> 00:28:03,129
to let you shuffle the deck.

516
00:28:03,129 --> 00:28:05,170
So go ahead and shuffle
it, do whatever you want.

517
00:28:05,170 --> 00:28:06,040
It's a normal deck.

518
00:28:06,040 --> 00:28:09,760
It's got 52 cards
and two jokers.

519
00:28:09,760 --> 00:28:12,970
And I don't care what
order they're in.

520
00:28:12,970 --> 00:28:16,410
I'm going to turn over
the cards one at a time.

521
00:28:16,410 --> 00:28:21,110
Now I'm going to ask you to
pick a number from 1 to 9

522
00:28:21,110 --> 00:28:22,200
ahead of time.

523
00:28:22,200 --> 00:28:24,530
Don't tell me or anybody else.

524
00:28:24,530 --> 00:28:27,550
In fact, I'm going to want
you guys to play along too.

525
00:28:27,550 --> 00:28:31,120
And we're going to see
where we all end up here.

526
00:28:31,120 --> 00:28:33,110
And that's your starting number.

527
00:28:33,110 --> 00:28:36,360
And as I turn over the
cards one at a time--

528
00:28:36,360 --> 00:28:39,630
say you started with a 3 was
the number you had in mind--

529
00:28:39,630 --> 00:28:44,100
on the third card I show,
that becomes your card.

530
00:28:44,100 --> 00:28:46,865
You don't tell me or jump
up and down or anything.

531
00:28:46,865 --> 00:28:47,740
But that's your card.

532
00:28:47,740 --> 00:28:52,650
And say it's a 4 of diamonds.

533
00:28:52,650 --> 00:28:55,110
Now a 4 replaces the
three in your mind

534
00:28:55,110 --> 00:29:00,130
and you count 4 more cards,
then that becomes your card.

535
00:29:00,130 --> 00:29:04,350
Now let's say that's a jack or
a face card or a 10 or a joker.

536
00:29:04,350 --> 00:29:06,840
10, face card, and
jokers all count as 1

537
00:29:06,840 --> 00:29:08,730
just like an ace counts as 1.

538
00:29:08,730 --> 00:29:10,940
And so then the next
card would be your card

539
00:29:10,940 --> 00:29:12,540
because you count 1.

540
00:29:12,540 --> 00:29:17,510
And we keep on going until you
have a card, maybe it's a 7.

541
00:29:17,510 --> 00:29:20,230
But there's only four
cards left in the deck.

542
00:29:20,230 --> 00:29:21,760
And so you don't get a new one.

543
00:29:21,760 --> 00:29:24,390
And your last card is the 7.

544
00:29:24,390 --> 00:29:29,300
And then you're going to write
that down here, not showing me.

545
00:29:29,300 --> 00:29:31,510
And you're going to
do this, maybe do this

546
00:29:31,510 --> 00:29:33,610
with a friend over there.

547
00:29:33,610 --> 00:29:36,030
And you're going to make sure
you count right on the deck

548
00:29:36,030 --> 00:29:37,571
because if you screw
up the counting,

549
00:29:37,571 --> 00:29:40,800
it's going to be hard
for me to read your mind.

550
00:29:40,800 --> 00:29:42,965
So just to make sure we
all understand this, let

551
00:29:42,965 --> 00:29:45,423
me write the rules down here
because I want the whole class

552
00:29:45,423 --> 00:29:49,270
to pick a number from 1 to
9 and play the same game.

553
00:29:49,270 --> 00:29:53,565
And we're going to
see what happens.

554
00:29:53,565 --> 00:29:55,190
So let me show you
the rules again just

555
00:29:55,190 --> 00:29:56,648
to make sure
everybody understands.

556
00:29:56,648 --> 00:29:59,520


557
00:29:59,520 --> 00:30:03,260
So say the deck
starts out like this.

558
00:30:03,260 --> 00:30:05,760
I got a 4, a 5.

559
00:30:05,760 --> 00:30:08,890
So my first few cards of
the deck go like this.

560
00:30:08,890 --> 00:30:10,410
10 equals a 1.

561
00:30:10,410 --> 00:30:12,630
Then I got a queen equals a 1.

562
00:30:12,630 --> 00:30:16,024
3, 7, 6, 4, 2.

563
00:30:16,024 --> 00:30:16,940
Say it's a small deck.

564
00:30:16,940 --> 00:30:19,740
I'm going to use 54 cards.

565
00:30:19,740 --> 00:30:26,420
And say you're chosen number to
start, you start with a three.

566
00:30:26,420 --> 00:30:29,030


567
00:30:29,030 --> 00:30:34,640
As I show the cards, you're
going to count 1, 2, 3.

568
00:30:34,640 --> 00:30:36,650
That becomes your new card.

569
00:30:36,650 --> 00:30:38,340
Then you're going to count 1, 2.

570
00:30:38,340 --> 00:30:39,430
That becomes your card.

571
00:30:39,430 --> 00:30:42,220
It's a 10, so you
convert it to a 1

572
00:30:42,220 --> 00:30:44,390
because we're only doing
single digit numbers.

573
00:30:44,390 --> 00:30:46,760
Go to 1, that becomes your card.

574
00:30:46,760 --> 00:30:47,910
Queen converts to a 1.

575
00:30:47,910 --> 00:30:49,520
You go 1, that
becomes your card.

576
00:30:49,520 --> 00:30:52,320
3, 1, 2, 3.

577
00:30:52,320 --> 00:30:54,730
That becomes your card.

578
00:30:54,730 --> 00:31:00,240
And you can't get 4, so you
remember the final card.

579
00:31:00,240 --> 00:31:03,230
Does everybody understand
what you're supposed to do?

580
00:31:03,230 --> 00:31:06,410
Because we're going to
do 54 cards of this.

581
00:31:06,410 --> 00:31:08,859
Maybe we get the TAs
to play along here.

582
00:31:08,859 --> 00:31:11,150
And as you do it, maybe you
want to talk to your buddy,

583
00:31:11,150 --> 00:31:12,940
make sure you got
it worked out there.

584
00:31:12,940 --> 00:31:16,742


585
00:31:16,742 --> 00:31:18,200
And if I could read
your mind maybe

586
00:31:18,200 --> 00:31:21,510
we'll have a gift
certificate or something.

587
00:31:21,510 --> 00:31:23,330
So you shuffle the deck?

588
00:31:23,330 --> 00:31:24,350
Got it good?

589
00:31:24,350 --> 00:31:24,880
All right.

590
00:31:24,880 --> 00:31:27,213
So I'm going to start revealing
the cards one at a time.

591
00:31:27,213 --> 00:31:30,190
So you guys play along
quietly in your mind.

592
00:31:30,190 --> 00:31:33,100
And we'll see if we can
concentrate long enough.

593
00:31:33,100 --> 00:31:42,750


594
00:31:42,750 --> 00:31:43,700
Aces are 1.

595
00:31:43,700 --> 00:31:59,950


596
00:31:59,950 --> 00:32:00,693
Jacks are 1.

597
00:32:00,693 --> 00:32:18,790


598
00:32:18,790 --> 00:32:19,550
10's are 1.

599
00:32:19,550 --> 00:33:27,530


600
00:33:27,530 --> 00:33:28,380
10's are 1.

601
00:33:28,380 --> 00:34:11,410


602
00:34:11,410 --> 00:34:12,840
We're halfway done.

603
00:34:12,840 --> 00:35:22,260


604
00:35:22,260 --> 00:35:23,650
Jokers are 1.

605
00:35:23,650 --> 00:35:28,471


606
00:35:28,471 --> 00:35:28,970
OK.

607
00:35:28,970 --> 00:35:30,070
That's the last card.

608
00:35:30,070 --> 00:35:32,111
So remember the last
one that was yours.

609
00:35:32,111 --> 00:35:33,735
And you got to go
check with your buddy

610
00:35:33,735 --> 00:35:38,592
to make sure you guys agree
on the counting there.

611
00:35:38,592 --> 00:35:39,550
And then write it down.

612
00:35:39,550 --> 00:35:43,840


613
00:35:43,840 --> 00:35:47,040
Don't tell me because I'm
going to read your mind.

614
00:35:47,040 --> 00:35:47,990
I'm going to tell you.

615
00:35:47,990 --> 00:35:53,312


616
00:35:53,312 --> 00:35:54,020
This is not good.

617
00:35:54,020 --> 00:35:57,690
They're arguing
over the last card.

618
00:35:57,690 --> 00:36:00,980
I'll have to read
one of your minds.

619
00:36:00,980 --> 00:36:01,480
What's that?

620
00:36:01,480 --> 00:36:02,286
The 11 of clubs.

621
00:36:02,286 --> 00:36:03,410
That's hard one to predict.

622
00:36:03,410 --> 00:36:12,976


623
00:36:12,976 --> 00:36:14,600
Make your best guess
and write it down.

624
00:36:14,600 --> 00:36:15,183
Don't tell me.

625
00:36:15,183 --> 00:36:16,152
Write it down.

626
00:36:16,152 --> 00:36:16,652
You got two?

627
00:36:16,652 --> 00:36:17,568
Well, write them both.

628
00:36:17,568 --> 00:36:18,780
I'll predict one of them.

629
00:36:18,780 --> 00:36:30,000


630
00:36:30,000 --> 00:36:32,704
I've never had a
dispute on what the--

631
00:36:32,704 --> 00:36:34,620
because if you started
with the same position,

632
00:36:34,620 --> 00:36:36,870
you've got to wind up
in the same position.

633
00:36:36,870 --> 00:36:38,244
You wrote it down?

634
00:36:38,244 --> 00:36:39,910
Now think about your
number really hard.

635
00:36:39,910 --> 00:36:40,690
We'll take yours.

636
00:36:40,690 --> 00:36:41,370
I'll trust you there.

637
00:36:41,370 --> 00:36:42,870
Think about it
really hard because I

638
00:36:42,870 --> 00:36:46,230
need the brain waves to come
over and read the mind here.

639
00:36:46,230 --> 00:36:49,900


640
00:36:49,900 --> 00:36:51,920
Yeah, yeah.

641
00:36:51,920 --> 00:36:55,559
I'm getting a really strong
signal on the last card.

642
00:36:55,559 --> 00:36:56,350
Maybe I don't know.

643
00:36:56,350 --> 00:36:58,183
Maybe it's something--
it's really powerful.

644
00:36:58,183 --> 00:37:00,941
I'm going to say it's
the queen of hearts.

645
00:37:00,941 --> 00:37:02,861
Is that right?

646
00:37:02,861 --> 00:37:05,360
Both were the queen of-- oh,
you were trying to screw me up,

647
00:37:05,360 --> 00:37:06,080
mess with me.

648
00:37:06,080 --> 00:37:09,066
So you both got the
queen of hearts.

649
00:37:09,066 --> 00:37:09,820
Oh, you did.

650
00:37:09,820 --> 00:37:14,030
So how many people got
the queen of hearts?

651
00:37:14,030 --> 00:37:14,530
Oh wow.

652
00:37:14,530 --> 00:37:18,200
How many people did not
get the queen of hearts.

653
00:37:18,200 --> 00:37:18,700
Somebody.

654
00:37:18,700 --> 00:37:19,680
OK.

655
00:37:19,680 --> 00:37:22,490
Now there's a chance
you did it legitimately.

656
00:37:22,490 --> 00:37:26,030
But usually, with
a deck, we're all

657
00:37:26,030 --> 00:37:28,329
going to get the same last card.

658
00:37:28,329 --> 00:37:30,620
Now in this case, it happened
to be the very last card.

659
00:37:30,620 --> 00:37:32,880
That is typically not the case.

660
00:37:32,880 --> 00:37:34,660
So very good.

661
00:37:34,660 --> 00:37:35,670
So I read your mind.

662
00:37:35,670 --> 00:37:38,670
So you guys get the
gift certificates here.

663
00:37:38,670 --> 00:37:39,170
Very good.

664
00:37:39,170 --> 00:37:42,220
One for you and
your sponsor there.

665
00:37:42,220 --> 00:37:47,300
So it's clear how I read
his mind because I got

666
00:37:47,300 --> 00:37:49,350
the same number everybody did.

667
00:37:49,350 --> 00:37:52,630
And somehow it doesn't
matter where we started.

668
00:37:52,630 --> 00:37:55,322
We all had the same
card at the end.

669
00:37:55,322 --> 00:37:58,150
How is that possible?

670
00:37:58,150 --> 00:38:00,874
There's nine different
starting points.

671
00:38:00,874 --> 00:38:02,790
Why don't we wind up in
nine different places?

672
00:38:02,790 --> 00:38:04,460
And why isn't there
a one in nine chance

673
00:38:04,460 --> 00:38:07,420
that I guess his card?

674
00:38:07,420 --> 00:38:10,829
Why do we all wind
up in the same place?

675
00:38:10,829 --> 00:38:11,370
Any thoughts?

676
00:38:11,370 --> 00:38:12,806
Yeah?

677
00:38:12,806 --> 00:38:13,972
AUDIENCE: Get the same card.

678
00:38:13,972 --> 00:38:16,525
After that you stay [INAUDIBLE].

679
00:38:16,525 --> 00:38:17,525
PROFESSOR: That's right.

680
00:38:17,525 --> 00:38:20,960
If ever we had the
same card, then we're

681
00:38:20,960 --> 00:38:23,910
going to track forever and
finish in the same card.

682
00:38:23,910 --> 00:38:25,710
But why should we ever
get the same card?

683
00:38:25,710 --> 00:38:29,605
What are the chances of that,
that we land on the same card?

684
00:38:29,605 --> 00:38:32,060


685
00:38:32,060 --> 00:38:33,810
Why don't we just keep
missing each other?

686
00:38:33,810 --> 00:38:35,410
It's a 1 in 9
chance or something.

687
00:38:35,410 --> 00:38:36,247
I don't know.

688
00:38:36,247 --> 00:38:37,330
Why don't we keep missing?

689
00:38:37,330 --> 00:38:39,420
AUDIENCE: It seems like
there are enough low cards

690
00:38:39,420 --> 00:38:42,130
that you just move slowly
along and, eventually, you're

691
00:38:42,130 --> 00:38:43,524
going to intersect.

692
00:38:43,524 --> 00:38:44,190
PROFESSOR: Yeah.

693
00:38:44,190 --> 00:38:47,060
I did make a lot
of 1's in the deck.

694
00:38:47,060 --> 00:38:48,460
If I would've made
all these face

695
00:38:48,460 --> 00:38:53,360
cards be 10's, the chances of
my reading your mind go down.

696
00:38:53,360 --> 00:38:55,300
Why do they go down?

697
00:38:55,300 --> 00:38:56,300
What does it have to do?

698
00:38:56,300 --> 00:39:00,320
Why did I put a lot
of 1's in the deck?

699
00:39:00,320 --> 00:39:01,770
AUDIENCE: It goes on longer.

700
00:39:01,770 --> 00:39:02,728
PROFESSOR: What's that?

701
00:39:02,728 --> 00:39:04,520
AUDIENCE: The game
goes on longer?

702
00:39:04,520 --> 00:39:05,978
PROFESSOR: The game
goes on longer.

703
00:39:05,978 --> 00:39:09,180
So there's more chances
to hit together.

704
00:39:09,180 --> 00:39:12,630
Because at any given time--
you've got your card.

705
00:39:12,630 --> 00:39:13,250
I've got mine.

706
00:39:13,250 --> 00:39:17,590
If mine is behind you, I
got a chance to land on you.

707
00:39:17,590 --> 00:39:19,170
And if you're behind
me in the deck,

708
00:39:19,170 --> 00:39:22,146
you've got a chance to land
on me with your number.

709
00:39:22,146 --> 00:39:23,770
And if the numbers
are smaller, there's

710
00:39:23,770 --> 00:39:27,190
more chances to
land on each other.

711
00:39:27,190 --> 00:39:30,010
And it is true that
on any given chance,

712
00:39:30,010 --> 00:39:33,300
the chances are low that
we land on the same card.

713
00:39:33,300 --> 00:39:35,990
But there's a lot of chances.

714
00:39:35,990 --> 00:39:37,610
And if there's a
lot more chances

715
00:39:37,610 --> 00:39:40,720
than the probability of
landing on each other,

716
00:39:40,720 --> 00:39:44,580
we've got Murphy's law.

717
00:39:44,580 --> 00:39:49,600
If you've got a lot of chances
and they're not less likely

718
00:39:49,600 --> 00:39:51,690
than the number of chances
or the inverse of that,

719
00:39:51,690 --> 00:39:53,880
then we expect to have
a certain bunch of times

720
00:39:53,880 --> 00:39:56,050
that we're going to
land on each other.

721
00:39:56,050 --> 00:39:59,970
And therefore, a very
high probability we do.

722
00:39:59,970 --> 00:40:02,240
Now that was a little hand-wavy.

723
00:40:02,240 --> 00:40:06,430


724
00:40:06,430 --> 00:40:09,210
And in fact, there's a
reason it was hand-wavy.

725
00:40:09,210 --> 00:40:13,510
Why doesn't Murphy's law
really apply in this case,

726
00:40:13,510 --> 00:40:14,711
really mathematically apply?

727
00:40:14,711 --> 00:40:15,210
Yeah.

728
00:40:15,210 --> 00:40:18,399


729
00:40:18,399 --> 00:40:20,190
AUDIENCE: They're not
mutually independent.

730
00:40:20,190 --> 00:40:23,940
Once you draw one card,
it's not coming back.

731
00:40:23,940 --> 00:40:25,240
PROFESSOR: That's correct.

732
00:40:25,240 --> 00:40:29,640
And it means that the knowledge
that we haven't collided yet

733
00:40:29,640 --> 00:40:32,670
tells me something about the
cards we've seen-- not a lot,

734
00:40:32,670 --> 00:40:34,670
but something maybe.

735
00:40:34,670 --> 00:40:37,080
And it's a finite
deck which tells me

736
00:40:37,080 --> 00:40:39,180
something about the
cards that are coming.

737
00:40:39,180 --> 00:40:40,840
And it might influence
the probability

738
00:40:40,840 --> 00:40:42,710
that we land together,
the next person

739
00:40:42,710 --> 00:40:45,390
who's jumping on the deck.

740
00:40:45,390 --> 00:40:48,870
And so the events of-- like
for example, in this case,

741
00:40:48,870 --> 00:40:54,930
we let A i be the event of a
collision on the i-th jump.

742
00:40:54,930 --> 00:40:58,000
And there's about 20 jumps in
this game, 10 for each of us

743
00:40:58,000 --> 00:40:58,500
expected.

744
00:40:58,500 --> 00:41:01,230


745
00:41:01,230 --> 00:41:06,935
So A i is the event that we
collide on the i-th jump.

746
00:41:06,935 --> 00:41:11,420


747
00:41:11,420 --> 00:41:15,710
These events are not necessarily
mutually independent.

748
00:41:15,710 --> 00:41:19,900
Now if I had an
infinite deck or a deck

749
00:41:19,900 --> 00:41:24,360
with replacement so every card
is equally likely to come next

750
00:41:24,360 --> 00:41:26,230
no matter what's
come in the past,

751
00:41:26,230 --> 00:41:28,630
now you can start getting
some mutual independence here.

752
00:41:28,630 --> 00:41:31,880
And then you could start
really applying the theorem.

753
00:41:31,880 --> 00:41:34,730
Now in this case, you don't
expect 10 things to happen.

754
00:41:34,730 --> 00:41:36,190
You expect a few.

755
00:41:36,190 --> 00:41:38,945
But that's good enough
that, in fact-- so

756
00:41:38,945 --> 00:41:40,990
we did a computer
simulation once

757
00:41:40,990 --> 00:41:44,300
and I got about a 90%
chance that we'll all

758
00:41:44,300 --> 00:41:45,970
be on the same card.

759
00:41:45,970 --> 00:41:48,640
So I have a pretty good chance
that I'm going to guess right.

760
00:41:48,640 --> 00:41:51,410
And so far, I haven't
guessed wrong.

761
00:41:51,410 --> 00:41:53,670
But it will happen
some day that we'll

762
00:41:53,670 --> 00:41:55,180
start with a different
first number,

763
00:41:55,180 --> 00:41:57,450
and we will miss at
the end because they'll

764
00:41:57,450 --> 00:41:59,954
be two possible outcomes.

765
00:41:59,954 --> 00:42:01,620
Just the way it works
out with 52 cards.

766
00:42:01,620 --> 00:42:03,320
Now of course, if
we have more cards

767
00:42:03,320 --> 00:42:07,020
or I made more things be
1's instead of 9's, say,

768
00:42:07,020 --> 00:42:10,290
my odds go up because the
number of events I've got,

769
00:42:10,290 --> 00:42:13,970
the number of chances
to collide, increases.

770
00:42:13,970 --> 00:42:17,920
And the chance of hitting
when I jump also increases.

771
00:42:17,920 --> 00:42:19,860
Any questions on that game?

772
00:42:19,860 --> 00:42:23,490


773
00:42:23,490 --> 00:42:28,090
So the point of all this is
that if the expected number

774
00:42:28,090 --> 00:42:31,730
of events to occur
is small, then

775
00:42:31,730 --> 00:42:33,400
it's an upper bound
on the probability

776
00:42:33,400 --> 00:42:38,550
that something happens, whether
they're independent or not.

777
00:42:38,550 --> 00:42:42,310
If the expected number of events
to occur is bigger than 1,

778
00:42:42,310 --> 00:42:46,390
large, and if the events
are mutually independent,

779
00:42:46,390 --> 00:42:49,140
then you can be sure
one of those events

780
00:42:49,140 --> 00:42:52,260
is going to occur-- very, very
likely one of them will occur.

781
00:42:52,260 --> 00:42:54,690
And that's Murphy's law.

782
00:42:54,690 --> 00:42:57,670
Any questions about
numbers of events to occur?

783
00:42:57,670 --> 00:43:01,930


784
00:43:01,930 --> 00:43:05,010
We'll talk more about the
probability in the numbers

785
00:43:05,010 --> 00:43:09,055
of events that occur next time.

786
00:43:09,055 --> 00:43:10,430
Before we do that,
I want to talk

787
00:43:10,430 --> 00:43:12,725
about some more useful
facts about expectation.

788
00:43:12,725 --> 00:43:16,100


789
00:43:16,100 --> 00:43:20,020
Now we know from
linearity of expectation

790
00:43:20,020 --> 00:43:24,330
that the expected value of
a sum of random variables

791
00:43:24,330 --> 00:43:30,550
is the sum of the expected
values of the random variables.

792
00:43:30,550 --> 00:43:34,600
Now we're going to look at the
expected value of a product

793
00:43:34,600 --> 00:43:36,660
of random variables.

794
00:43:36,660 --> 00:43:38,965
And it turns out there's
a very nice rule for that.

795
00:43:38,965 --> 00:43:41,530


796
00:43:41,530 --> 00:43:46,845
Theorem 4, and it's the
product rule for expectation.

797
00:43:46,845 --> 00:43:53,010


798
00:43:53,010 --> 00:43:57,000
And it says that for-- if
your random variables are

799
00:43:57,000 --> 00:44:09,140
independent, R1 and
R2 are independent,

800
00:44:09,140 --> 00:44:12,855
then the expected value
of their product, also

801
00:44:12,855 --> 00:44:17,510
a random variable, is simply the
product of the expected values.

802
00:44:17,510 --> 00:44:20,150


803
00:44:20,150 --> 00:44:23,650
So it's sort of the
equivalent thing

804
00:44:23,650 --> 00:44:26,672
to linearity of expectation,
except we're doing products.

805
00:44:26,672 --> 00:44:27,755
And you need independence.

806
00:44:27,755 --> 00:44:31,781


807
00:44:31,781 --> 00:44:34,280
Now the proof of this is not
too hard, and it's in the book.

808
00:44:34,280 --> 00:44:37,061
So we're not going
to do it in class.

809
00:44:37,061 --> 00:44:38,185
But we can give an example.

810
00:44:38,185 --> 00:44:41,030


811
00:44:41,030 --> 00:44:52,820
Say we roll two six-sided
fair and independent dice.

812
00:44:52,820 --> 00:44:58,230


813
00:44:58,230 --> 00:45:02,130
And I want to know what's the
expected product of the dice.

814
00:45:02,130 --> 00:45:10,900


815
00:45:10,900 --> 00:45:18,720
So we're going to let R1 be
the value on the first die,

816
00:45:18,720 --> 00:45:22,355
and R2 would be the
value on the second one.

817
00:45:22,355 --> 00:45:25,060


818
00:45:25,060 --> 00:45:31,670
And the expected
value of the product

819
00:45:31,670 --> 00:45:33,320
is the product of
the expectations.

820
00:45:33,320 --> 00:45:37,910


821
00:45:37,910 --> 00:45:43,160
And we already know the expected
value of a single die is 7/2.

822
00:45:43,160 --> 00:45:49,260
So we get 7/2 times 7/2
is 49/4 or 12 and 1/4.

823
00:45:49,260 --> 00:45:55,400
So it's easy to compute the
expected product of two dice.

824
00:45:55,400 --> 00:45:57,200
Any questions about that?

825
00:45:57,200 --> 00:46:00,910


826
00:46:00,910 --> 00:46:06,200
Much easier than looking at all
36 outcomes to use this rule.

827
00:46:06,200 --> 00:46:11,350
Now what if the dice we're
rigged, glued together somehow

828
00:46:11,350 --> 00:46:12,790
so they always came up the same?

829
00:46:12,790 --> 00:46:15,780


830
00:46:15,780 --> 00:46:18,540
Would the expected
product B 12 and 1/4 then?

831
00:46:18,540 --> 00:46:21,990


832
00:46:21,990 --> 00:46:22,610
No?

833
00:46:22,610 --> 00:46:24,460
Why not?

834
00:46:24,460 --> 00:46:26,060
Why wouldn't it be the case?

835
00:46:26,060 --> 00:46:29,670


836
00:46:29,670 --> 00:46:31,890
Why isn't the
expected value of R1

837
00:46:31,890 --> 00:46:37,060
squared the square of
the expected value of R1?

838
00:46:37,060 --> 00:46:40,174
Isn't that what this says?

839
00:46:40,174 --> 00:46:41,150
AUDIENCE: Independent.

840
00:46:41,150 --> 00:46:42,730
PROFESSOR: They're
not independent.

841
00:46:42,730 --> 00:46:47,120
R1 is not independent of R1
In fact, it's the same thing.

842
00:46:47,120 --> 00:46:50,490
And you need independence
for that to be the case.

843
00:46:50,490 --> 00:47:02,140
So a non example, the
expected value of R1 times R1

844
00:47:02,140 --> 00:47:07,950
is the expected
value of R1 squared.

845
00:47:07,950 --> 00:47:10,210
And to do that, we got
to go back to the basics.

846
00:47:10,210 --> 00:47:12,805
We're taking the six
possible values of R1.

847
00:47:12,805 --> 00:47:15,400
i equals 1 to 6.

848
00:47:15,400 --> 00:47:18,550
i squared, because
we're squaring it,

849
00:47:18,550 --> 00:47:21,060
times the probability
R1 equals i.

850
00:47:21,060 --> 00:47:23,660


851
00:47:23,660 --> 00:47:26,020
And each of those
probabilities is 1/6.

852
00:47:26,020 --> 00:47:36,470
So we get 1/6 times 1 plus 4
plus 9 plus 16 plus 25 plus 36.

853
00:47:36,470 --> 00:47:42,250
And if you add all that
up you get 15 and 1/6,

854
00:47:42,250 --> 00:47:50,180
which is not 3 and 1/2
squared, which is the expected

855
00:47:50,180 --> 00:47:54,340
value of R1 squared.

856
00:47:54,340 --> 00:47:56,660
So the expected
value of the square

857
00:47:56,660 --> 00:48:01,150
is not necessarily the
square of the expectation.

858
00:48:01,150 --> 00:48:03,774
Because a random variable
is not independent of itself

859
00:48:03,774 --> 00:48:04,273
generally.

860
00:48:04,273 --> 00:48:07,450


861
00:48:07,450 --> 00:48:08,190
OK.

862
00:48:08,190 --> 00:48:10,270
Any questions there?

863
00:48:10,270 --> 00:48:12,492


864
00:48:12,492 --> 00:48:14,075
There's a couple of
quick corollaries.

865
00:48:14,075 --> 00:48:19,250


866
00:48:19,250 --> 00:48:21,590
The first is you take
this rule and apply it

867
00:48:21,590 --> 00:48:26,067
to many random variables as long
as they're mutually dependent.

868
00:48:26,067 --> 00:48:40,580
So if R1 R2 out to R n
are mutually independent,

869
00:48:40,580 --> 00:48:48,620
then the expected
value of their product

870
00:48:48,620 --> 00:48:50,510
is the product of
the expected values.

871
00:48:50,510 --> 00:48:59,720


872
00:48:59,720 --> 00:49:03,620
And the proof is just by
induction on the number

873
00:49:03,620 --> 00:49:04,550
of random variables.

874
00:49:04,550 --> 00:49:06,439
So that's pretty easy.

875
00:49:06,439 --> 00:49:07,730
There's another easy corollary.

876
00:49:07,730 --> 00:49:11,718


877
00:49:11,718 --> 00:49:19,670
And that says, for any
constants, constant values,

878
00:49:19,670 --> 00:49:28,150
a and b, and any
random variable R,

879
00:49:28,150 --> 00:49:35,460
the expected value of a times
R plus b is simply a times

880
00:49:35,460 --> 00:49:38,760
the expected value of R plus b.

881
00:49:38,760 --> 00:49:41,360


882
00:49:41,360 --> 00:49:43,860
And the reason that's
true-- well, the sum

883
00:49:43,860 --> 00:49:47,300
works because of linearity
of expectation for the sum.

884
00:49:47,300 --> 00:49:50,030
You can think of b as a random
variable that just always

885
00:49:50,030 --> 00:49:52,950
has the value b.

886
00:49:52,950 --> 00:49:56,862
And the a comes out
in front because you

887
00:49:56,862 --> 00:49:58,570
can think of it as a
random variable that

888
00:49:58,570 --> 00:50:01,225
always has a value a.

889
00:50:01,225 --> 00:50:04,240
And that's independent of
any other random variable

890
00:50:04,240 --> 00:50:06,630
because it never changes.

891
00:50:06,630 --> 00:50:10,325
So by the product rule,
the a can come out.

892
00:50:10,325 --> 00:50:11,700
Now you've got to
prove all that.

893
00:50:11,700 --> 00:50:14,159
But it's not too hard and
not especially interesting.

894
00:50:14,159 --> 00:50:15,200
So we won't do that here.

895
00:50:15,200 --> 00:50:18,372


896
00:50:18,372 --> 00:50:19,455
Any questions about those?

897
00:50:19,455 --> 00:50:27,140


898
00:50:27,140 --> 00:50:28,530
So we've got a
rule for computing

899
00:50:28,530 --> 00:50:32,170
the sum of random variables,
a rule for the product

900
00:50:32,170 --> 00:50:34,420
of random variables.

901
00:50:34,420 --> 00:50:39,350
What about a rule for the
ratio of random variables?

902
00:50:39,350 --> 00:50:40,280
Let's look at that.

903
00:50:40,280 --> 00:50:45,330


904
00:50:45,330 --> 00:50:47,600
So is this the corollary?

905
00:50:47,600 --> 00:50:50,490


906
00:50:50,490 --> 00:50:52,890
In fact, let's take the
inverse of random variable.

907
00:50:52,890 --> 00:50:57,690
Is the expected value
of 1/R equal to 1

908
00:50:57,690 --> 00:51:04,510
over the expected value of
R for any random variable R?

909
00:51:04,510 --> 00:51:06,560
Some folks saying yes.

910
00:51:06,560 --> 00:51:09,240
Some saying no.

911
00:51:09,240 --> 00:51:10,350
What do you think?

912
00:51:10,350 --> 00:51:11,445
Is that true?

913
00:51:11,445 --> 00:51:14,610


914
00:51:14,610 --> 00:51:15,790
Oh, got a mix.

915
00:51:15,790 --> 00:51:17,910
How many say yes?

916
00:51:17,910 --> 00:51:19,385
How many say no?

917
00:51:19,385 --> 00:51:20,500
Oh, more no's.

918
00:51:20,500 --> 00:51:22,940
Somebody tell me
why that's not true.

919
00:51:22,940 --> 00:51:26,058
Who would like to
give me an example?

920
00:51:26,058 --> 00:51:31,345
Give us an example there
that'll be very convincing.

921
00:51:31,345 --> 00:51:33,954
Yeah?

922
00:51:33,954 --> 00:51:36,370
AUDIENCE: I don't think it's
one that would be immediately

923
00:51:36,370 --> 00:51:41,558
obvious, but I think if R is
the result of the roll of a die,

924
00:51:41,558 --> 00:51:43,900
I don't think it works out.

925
00:51:43,900 --> 00:51:47,060
PROFESSOR: So it's 50
chance of-- oh, I see.

926
00:51:47,060 --> 00:51:53,159
So I take the average of 1/i--
that's sort of hard to compute.

927
00:51:53,159 --> 00:51:55,200
I got to do [INAUDIBLE]
the sixth harmonic number

928
00:51:55,200 --> 00:51:56,825
and then invert it.

929
00:51:56,825 --> 00:52:00,439
There's an easier way to
show that this is false.

930
00:52:00,439 --> 00:52:00,938
Yeah?

931
00:52:00,938 --> 00:52:02,869
AUDIENCE: The expected
value equals 0?

932
00:52:02,869 --> 00:52:03,535
PROFESSOR: Yeah.

933
00:52:03,535 --> 00:52:07,330
The expected value
equals 0 which

934
00:52:07,330 --> 00:52:12,520
could happen if R is plus 1
or minus 1 equally likely.

935
00:52:12,520 --> 00:52:15,840
So here's an example here.

936
00:52:15,840 --> 00:52:23,640
So R equals 1 with
probability 1/2, and minus 1

937
00:52:23,640 --> 00:52:25,500
with probability 1/2.

938
00:52:25,500 --> 00:52:27,835
So the expected value of R is 0.

939
00:52:27,835 --> 00:52:32,370


940
00:52:32,370 --> 00:52:33,370
So that blows up.

941
00:52:33,370 --> 00:52:34,625
That's infinity.

942
00:52:34,625 --> 00:52:36,000
What's the expected
value of 1/R?

943
00:52:36,000 --> 00:52:41,320


944
00:52:41,320 --> 00:52:44,300
Well, 1/1 and 1 over
minus 1, it's the same.

945
00:52:44,300 --> 00:52:46,300
It equals 0.

946
00:52:46,300 --> 00:52:48,930
And this would say 0 equals 1/0.

947
00:52:48,930 --> 00:52:50,030
That's not true.

948
00:52:50,030 --> 00:52:51,980
So this is false.

949
00:52:51,980 --> 00:52:54,230
It is not true for
every random variable.

950
00:52:54,230 --> 00:52:57,350


951
00:52:57,350 --> 00:53:00,180
So once you see this example,
just obviously not true.

952
00:53:00,180 --> 00:53:02,010
In fact, there's very
few random variables

953
00:53:02,010 --> 00:53:06,440
for which this is true, even
an indicator random variable.

954
00:53:06,440 --> 00:53:11,290
So it's 1 with probability 1/2
and 0 with probability 1/2.

955
00:53:11,290 --> 00:53:14,950
Then the expected value
of 1/R is infinite.

956
00:53:14,950 --> 00:53:16,790
1 over the expected
value of R is 2.

957
00:53:16,790 --> 00:53:20,940


958
00:53:20,940 --> 00:53:24,570
So it's clearly not true.

959
00:53:24,570 --> 00:53:27,066
Let's do another one.

960
00:53:27,066 --> 00:53:34,730


961
00:53:34,730 --> 00:53:37,090
What about this
potential corollary?

962
00:53:37,090 --> 00:53:42,310


963
00:53:42,310 --> 00:53:53,530
Given independent random
variables R and T,

964
00:53:53,530 --> 00:54:02,570
if the expected value
or R/T is bigger than 1,

965
00:54:02,570 --> 00:54:07,630
then the expected value of R
is bigger than the expected

966
00:54:07,630 --> 00:54:15,970
value of T. And let me even give
you a potential proof of this,

967
00:54:15,970 --> 00:54:18,960
see if you like this proof.

968
00:54:18,960 --> 00:54:22,270
Well, let's assume the expected
value of R/T is bigger than 1.

969
00:54:22,270 --> 00:54:25,970


970
00:54:25,970 --> 00:54:39,620
And let's multiply both sides
by the expected value of T.

971
00:54:39,620 --> 00:54:42,530
And well, the product rule
says that this is just

972
00:54:42,530 --> 00:54:48,830
the expected value
of R/T times T, which

973
00:54:48,830 --> 00:54:51,990
is just the expected value
of R because the T's cancel.

974
00:54:51,990 --> 00:55:02,654


975
00:55:02,654 --> 00:55:03,570
So I gave you a proof.

976
00:55:03,570 --> 00:55:06,370


977
00:55:06,370 --> 00:55:09,760
Anybody have any
quibbles with this proof?

978
00:55:09,760 --> 00:55:15,172


979
00:55:15,172 --> 00:55:15,672
Yeah?

980
00:55:15,672 --> 00:55:19,050


981
00:55:19,050 --> 00:55:20,330
That's a big problem.

982
00:55:20,330 --> 00:55:23,680
R/T is not independent
of T. [INAUDIBLE]

983
00:55:23,680 --> 00:55:28,240
if T is very big, likely
that R/T is small.

984
00:55:28,240 --> 00:55:30,280
So we can't do that step.

985
00:55:30,280 --> 00:55:34,950
We can't use the independence
here to go from here to here.

986
00:55:34,950 --> 00:55:36,030
That's wrong.

987
00:55:36,030 --> 00:55:39,474
There's actually another
big problem with this proof.

988
00:55:39,474 --> 00:55:40,640
Anybody see another problem?

989
00:55:40,640 --> 00:55:41,140
Yeah?

990
00:55:41,140 --> 00:55:43,990


991
00:55:43,990 --> 00:55:44,880
Yeah.

992
00:55:44,880 --> 00:55:47,840
If the expected value
of T is negative,

993
00:55:47,840 --> 00:55:50,440
I would end up doing that.

994
00:55:50,440 --> 00:55:52,030
So that step's wrong.

995
00:55:52,030 --> 00:55:53,600
So this is a pretty lousy proof.

996
00:55:53,600 --> 00:55:55,900
Every step is wrong.

997
00:55:55,900 --> 00:55:58,170
So this is not a
good one to use.

998
00:55:58,170 --> 00:56:04,780
And in fact, the
theorem is wrong.

999
00:56:04,780 --> 00:56:07,100
Not only is the proof wrong,
but the result is wrong.

1000
00:56:07,100 --> 00:56:08,950
It's not true.

1001
00:56:08,950 --> 00:56:11,890
And we can see examples.

1002
00:56:11,890 --> 00:56:13,840
We'll do some
examples in a minute.

1003
00:56:13,840 --> 00:56:16,350
Now the amazing thing is that
despite the fact that this

1004
00:56:16,350 --> 00:56:21,610
is just blatantly wrong,
it is used all the time

1005
00:56:21,610 --> 00:56:23,270
in research papers.

1006
00:56:23,270 --> 00:56:26,280
And let me give you
a famous example.

1007
00:56:26,280 --> 00:56:32,430
This is a case of, actually, a
pretty well-known paper written

1008
00:56:32,430 --> 00:56:36,090
by some very famous computer
science professors at Berkeley.

1009
00:56:36,090 --> 00:56:38,640


1010
00:56:38,640 --> 00:56:42,130
And let me show
you what they did.

1011
00:56:42,130 --> 00:56:45,950
And this is so that
you will never do this.

1012
00:56:45,950 --> 00:56:54,870
They were trying to compare
two instruction sets way back

1013
00:56:54,870 --> 00:56:55,510
in the day.

1014
00:56:55,510 --> 00:56:58,750
And they were comparing
the RISC architecture

1015
00:56:58,750 --> 00:57:01,740
to something called the Z8002.

1016
00:57:01,740 --> 00:57:04,260
And they were
proponents of RISC.

1017
00:57:04,260 --> 00:57:07,600
And they were using this to
prove that it was a better way

1018
00:57:07,600 --> 00:57:09,290
to do things.

1019
00:57:09,290 --> 00:57:14,290
So they had a bunch of benchmark
problems, probably 20 or so

1020
00:57:14,290 --> 00:57:14,940
in the paper.

1021
00:57:14,940 --> 00:57:16,520
And I'm not going
to do all 20 here.

1022
00:57:16,520 --> 00:57:19,210
I'm going to give you a flavor
for what the data showed.

1023
00:57:19,210 --> 00:57:27,110
And then they looked at
the code size for RISC

1024
00:57:27,110 --> 00:57:32,182
and the other guys, Z8002.

1025
00:57:32,182 --> 00:57:33,390
And then they took the ratio.

1026
00:57:33,390 --> 00:57:40,020


1027
00:57:40,020 --> 00:57:44,720
So the first problem was
called E-string search,

1028
00:57:44,720 --> 00:57:45,440
whatever that is.

1029
00:57:45,440 --> 00:57:48,820
But it was some benchmark
problem out there at the time.

1030
00:57:48,820 --> 00:57:51,510
And the code length
on RISC was 150

1031
00:57:51,510 --> 00:57:53,450
say-- I've changed these
numbers a little bit

1032
00:57:53,450 --> 00:57:54,820
to make them simpler.

1033
00:57:54,820 --> 00:57:58,930
Code length here and
the Z8002 is 120.

1034
00:57:58,930 --> 00:58:01,270
The ratio is 0.8.

1035
00:58:01,270 --> 00:58:05,020
So for this problem, you're
trying to get low, short code.

1036
00:58:05,020 --> 00:58:08,410
So this was a better way
to go to support that.

1037
00:58:08,410 --> 00:58:12,640
And they had something
called F-bit test.

1038
00:58:12,640 --> 00:58:14,530
And here you have 120 lines.

1039
00:58:14,530 --> 00:58:16,750
Here's 180.

1040
00:58:16,750 --> 00:58:20,260
So in this case, risk is better.

1041
00:58:20,260 --> 00:58:26,500
So the ratio of that way
to this way would be 1.5.

1042
00:58:26,500 --> 00:58:28,465
And they had computing
and Ackermann function.

1043
00:58:28,465 --> 00:58:31,540


1044
00:58:31,540 --> 00:58:34,260
And that was 150 and 300.

1045
00:58:34,260 --> 00:58:39,390
So a big win for
RISC, ratio of 2.

1046
00:58:39,390 --> 00:58:45,690
And then they had a thing called
recursive sorting problem.

1047
00:58:45,690 --> 00:58:47,530
This is a hard problem.

1048
00:58:47,530 --> 00:58:50,040
There's 2,800 lines on RISC.

1049
00:58:50,040 --> 00:58:54,190
1400 on the old way.

1050
00:58:54,190 --> 00:58:57,200
Ratio of 0.5.

1051
00:58:57,200 --> 00:59:00,400
And there was a bunch more which
I'm not going to go through.

1052
00:59:00,400 --> 00:59:04,470
But their analysis, what they
did is they took the ratio,

1053
00:59:04,470 --> 00:59:06,380
and then they averaged it.

1054
00:59:06,380 --> 00:59:12,715
And so when you do this, you get
an average of, well, 2.3, 4.3,

1055
00:59:12,715 --> 00:59:19,250
4.8/4 is 1.2.

1056
00:59:19,250 --> 00:59:23,890
So the conclusion is that on
average code in this framework

1057
00:59:23,890 --> 00:59:27,400
is 20% longer than
the code on RISC.

1058
00:59:27,400 --> 00:59:30,100
Therefore, clearly, RISC
is a better way to go.

1059
00:59:30,100 --> 00:59:33,020
Your code on average
will be shorter.

1060
00:59:33,020 --> 00:59:38,080
Using the Z8002 on average,
the code will be 20% longer.

1061
00:59:38,080 --> 00:59:39,246
Makes perfect sense, right?

1062
00:59:39,246 --> 00:59:42,162


1063
00:59:42,162 --> 00:59:44,840
In fact, this is one of
the most common things

1064
00:59:44,840 --> 00:59:47,133
that is done when people
are comparing two systems.

1065
00:59:47,133 --> 00:59:50,514


1066
00:59:50,514 --> 00:59:56,420
Now just one problem with
this approach, and that's

1067
00:59:56,420 --> 00:59:59,840
that it's completely
bogus, completely bogus.

1068
00:59:59,840 --> 01:00:02,820
You cannot conclude--
let's make this conclusion.

1069
01:00:02,820 --> 01:00:13,090
So their conclusion, they
concluded that Z8002 programs

1070
01:00:13,090 --> 01:00:17,905
are 20% longer on average.

1071
01:00:17,905 --> 01:00:24,890


1072
01:00:24,890 --> 01:00:28,110
Everybody understands
the reasoning why, right?

1073
01:00:28,110 --> 01:00:31,875
Take the ratio of all the
test cases, average them up.

1074
01:00:31,875 --> 01:00:33,410
Then you get the average ratio.

1075
01:00:33,410 --> 01:00:38,380


1076
01:00:38,380 --> 01:00:41,030
Now there could be some
hint why this is bogus.

1077
01:00:41,030 --> 01:00:45,000
If I just looked at--
I took and summed

1078
01:00:45,000 --> 01:00:51,670
these numbers, if I add all
those numbers up, I get 3,220.

1079
01:00:51,670 --> 01:00:55,570
And all these, I get 2,000.

1080
01:00:55,570 --> 01:00:59,500
RISC code is not looking
shorter if I do that.

1081
01:00:59,500 --> 01:01:02,340
Looking longer.

1082
01:01:02,340 --> 01:01:08,200
But all that gain, all the loss
of RISC is in this one problem.

1083
01:01:08,200 --> 01:01:10,960
And maybe it's not
fair to do that.

1084
01:01:10,960 --> 01:01:14,537
And that's why when people
have data like this,

1085
01:01:14,537 --> 01:01:15,620
they just take the ratios.

1086
01:01:15,620 --> 01:01:20,110
Because now it would be-- if
I just took the average code

1087
01:01:20,110 --> 01:01:22,290
length and took
the ratio of that,

1088
01:01:22,290 --> 01:01:23,950
it's not fair because
one problem just

1089
01:01:23,950 --> 01:01:26,409
wiped out the whole thing.

1090
01:01:26,409 --> 01:01:27,700
I might as well not even do it.

1091
01:01:27,700 --> 01:01:29,880
And they want every
problem to count equally.

1092
01:01:29,880 --> 01:01:32,210
And that's why they
take the ratio,

1093
01:01:32,210 --> 01:01:34,840
to make them all count equally.

1094
01:01:34,840 --> 01:01:36,330
Let's do one more thing here.

1095
01:01:36,330 --> 01:01:44,130
Let's look at what happens
if we take the ratio of RISC

1096
01:01:44,130 --> 01:01:47,356
to the Z8002.

1097
01:01:47,356 --> 01:01:48,355
Make some room for that.

1098
01:01:48,355 --> 01:01:54,630
So this is-- this column
is Z8002 over RISC.

1099
01:01:54,630 --> 01:02:00,930
What if I just did this--
RISC over the Z8002 I mean

1100
01:02:00,930 --> 01:02:03,754
the answer should come
out to 1/1.2, right?

1101
01:02:03,754 --> 01:02:05,420
That's what we expect,
because I've just

1102
01:02:05,420 --> 01:02:07,820
been turning it upside down.

1103
01:02:07,820 --> 01:02:10,490
Well, I get 1.25 here.

1104
01:02:10,490 --> 01:02:12,100
These are just being inverted.

1105
01:02:12,100 --> 01:02:14,386
Here I've got 2/3, 0.67.

1106
01:02:14,386 --> 01:02:15,010
Here I get 1/2.

1107
01:02:15,010 --> 01:02:18,500


1108
01:02:18,500 --> 01:02:19,440
Here I get 2.

1109
01:02:19,440 --> 01:02:22,400


1110
01:02:22,400 --> 01:02:23,815
Let's add those up.

1111
01:02:23,815 --> 01:02:32,250
I get 1.92, 2.42, 4.42.

1112
01:02:32,250 --> 01:02:38,020
Divide by 4-- wow,
I get 1.1 something

1113
01:02:38,020 --> 01:02:41,100
which says, well, that
on average, RISC is

1114
01:02:41,100 --> 01:02:44,740
10% longer than the other one.

1115
01:02:44,740 --> 01:02:50,430
So same analysis says
that RISC programs

1116
01:02:50,430 --> 01:02:54,010
are 10% longer on average.

1117
01:02:54,010 --> 01:02:57,430


1118
01:02:57,430 --> 01:03:00,210
Now the beauty of
this method is you

1119
01:03:00,210 --> 01:03:05,410
can make any conclusion you
want seem reasonable, typically.

1120
01:03:05,410 --> 01:03:08,590
You could have the
exact same data.

1121
01:03:08,590 --> 01:03:13,330
And if you want RISC to look
better you do it this way.

1122
01:03:13,330 --> 01:03:17,720
If you want RISC to look
worse, you do it that way.

1123
01:03:17,720 --> 01:03:18,540
You see?

1124
01:03:18,540 --> 01:03:19,690
Is that possible?

1125
01:03:19,690 --> 01:03:21,470
Is it possible for
one to be 20% longer

1126
01:03:21,470 --> 01:03:24,026
than the other on average,
but the other be 10% longer

1127
01:03:24,026 --> 01:03:24,525
on average?

1128
01:03:24,525 --> 01:03:27,040


1129
01:03:27,040 --> 01:03:29,000
How many people think
that's possible?

1130
01:03:29,000 --> 01:03:31,440
We had some weird things
happen in this class,

1131
01:03:31,440 --> 01:03:33,650
but that's not possible.

1132
01:03:33,650 --> 01:03:34,830
That can't happen.

1133
01:03:34,830 --> 01:03:36,430
These conclusions
are both bogus.

1134
01:03:36,430 --> 01:03:41,090


1135
01:03:41,090 --> 01:03:44,210
Now I'm not teaching you
this so that later when

1136
01:03:44,210 --> 01:03:46,510
you're doing your PhD thesis
and it's down to the wire

1137
01:03:46,510 --> 01:03:49,250
and you need a conclusion
to be proved, good news.

1138
01:03:49,250 --> 01:03:51,240
You can prove it.

1139
01:03:51,240 --> 01:03:53,957
No matter what your conclusion
is, you can prove it.

1140
01:03:53,957 --> 01:03:55,290
That's not why we're doing this.

1141
01:03:55,290 --> 01:03:58,831
We're doing this so you can spot
the flaw in this whole setup

1142
01:03:58,831 --> 01:04:00,080
and that you'll never do this.

1143
01:04:00,080 --> 01:04:02,538
And you'll see it when other
people do because people do it

1144
01:04:02,538 --> 01:04:03,190
all the time.

1145
01:04:03,190 --> 01:04:06,160


1146
01:04:06,160 --> 01:04:09,460
So let's try to put some
formality under this

1147
01:04:09,460 --> 01:04:10,460
in terms of probability.

1148
01:04:10,460 --> 01:04:12,607
Because when you start
talking about averages,

1149
01:04:12,607 --> 01:04:15,190
really think about expectations
of random variables and stuff.

1150
01:04:15,190 --> 01:04:19,970
So let's try to view this
as a probability problem

1151
01:04:19,970 --> 01:04:22,410
and see if we can shed
some light on what's

1152
01:04:22,410 --> 01:04:25,480
going on here because it
sure seemed reasonable.

1153
01:04:25,480 --> 01:04:35,850


1154
01:04:35,850 --> 01:04:41,890
So let's let x be the benchmark.

1155
01:04:41,890 --> 01:04:45,400
And maybe that'll be
something in the sample space,

1156
01:04:45,400 --> 01:04:47,280
an outcome in the sample space.

1157
01:04:47,280 --> 01:05:00,490
Let's let R x be the code
length for RISC on x and Z x

1158
01:05:00,490 --> 01:05:09,340
be the code length for
the other processor on x.

1159
01:05:09,340 --> 01:05:19,060
And then we'll define a
probability of seeing x.

1160
01:05:19,060 --> 01:05:21,560
That's our problem
we're looking at.

1161
01:05:21,560 --> 01:05:28,290
And typically, you might
assume that it's uniform,

1162
01:05:28,290 --> 01:05:30,790
the distribution there.

1163
01:05:30,790 --> 01:05:33,830
We need this to be able to
define an expected value

1164
01:05:33,830 --> 01:05:37,350
for R and for Z.

1165
01:05:37,350 --> 01:05:42,610
Now what they're doing in the
paper, what really is happening

1166
01:05:42,610 --> 01:05:50,230
here, is instead of this, they
have the expected value of Z/R

1167
01:05:50,230 --> 01:05:52,160
is 1.2.

1168
01:05:52,160 --> 01:05:54,880
That is what they can conclude.

1169
01:05:54,880 --> 01:06:01,630
That does not mean that
the expected value of Z

1170
01:06:01,630 --> 01:06:05,350
is 1.2, the expected
value of R, which

1171
01:06:05,350 --> 01:06:10,200
is what they conclude
that the Z8002 code is

1172
01:06:10,200 --> 01:06:12,430
20% longer than RISC code.

1173
01:06:12,430 --> 01:06:14,860
This is true.

1174
01:06:14,860 --> 01:06:16,160
That is not implied.

1175
01:06:16,160 --> 01:06:19,070


1176
01:06:19,070 --> 01:06:21,506
And why not?

1177
01:06:21,506 --> 01:06:26,909
That's just, actually, what
this corollary was doing.

1178
01:06:26,909 --> 01:06:28,450
Really, it's just
what we were-- they

1179
01:06:28,450 --> 01:06:33,100
made the same false assumption
as happened in the corollary.

1180
01:06:33,100 --> 01:06:37,210
You can't multiply both sides
here by the expected value of R

1181
01:06:37,210 --> 01:06:41,240
and then get the expected value
Z. Of course, if you ask them,

1182
01:06:41,240 --> 01:06:43,066
they would have known that.

1183
01:06:43,066 --> 01:06:44,440
But they don't
even think through

1184
01:06:44,440 --> 01:06:46,523
that, they just used the
standard method of taking

1185
01:06:46,523 --> 01:06:49,290
the expected value of a ratio.

1186
01:06:49,290 --> 01:06:51,220
So this is fair to conclude.

1187
01:06:51,220 --> 01:06:58,340
But as we saw, the expected
value of R/Z was 1.1.

1188
01:06:58,340 --> 01:07:00,950
So both of these can be
true at the same time.

1189
01:07:00,950 --> 01:07:01,960
That's fine.

1190
01:07:01,960 --> 01:07:03,420
But you can't make
the conclusions

1191
01:07:03,420 --> 01:07:04,419
that they tried to make.

1192
01:07:04,419 --> 01:07:08,000


1193
01:07:08,000 --> 01:07:11,470
Here's another-- in
fact, in this case,

1194
01:07:11,470 --> 01:07:14,100
if we had a uniform
distribution,

1195
01:07:14,100 --> 01:07:21,396
the expected value of R
is like 805 for uniform.

1196
01:07:21,396 --> 01:07:28,990
And the expected
value of Z is 500.

1197
01:07:28,990 --> 01:07:31,254
And that's all you
can conclude if you're

1198
01:07:31,254 --> 01:07:32,420
taking uniform distribution.

1199
01:07:32,420 --> 01:07:36,310
In which case, of course,
if they're promoting RISC,

1200
01:07:36,310 --> 01:07:39,240
well, you don't like
that conclusion.

1201
01:07:39,240 --> 01:07:41,739
So it's better to
get this one's.

1202
01:07:41,739 --> 01:07:43,530
I don't think it was
intentional of course.

1203
01:07:43,530 --> 01:07:46,690
But it's nice that
it came out that way.

1204
01:07:46,690 --> 01:07:49,430


1205
01:07:49,430 --> 01:07:53,770
Here's another example that
really makes it painfully clear

1206
01:07:53,770 --> 01:07:57,060
why you never want to do this.

1207
01:07:57,060 --> 01:08:02,150
So a really simple case, just
generic variables R and Z.

1208
01:08:02,150 --> 01:08:08,550
And I got two problems only--
problem one, problem two.

1209
01:08:08,550 --> 01:08:11,020
R is 2 for problem
1, and z is 1.

1210
01:08:11,020 --> 01:08:12,768
And they reverse on problem 2.

1211
01:08:12,768 --> 01:08:15,396


1212
01:08:15,396 --> 01:08:19,205
Z/R is 2 and 1/2.

1213
01:08:19,205 --> 01:08:21,760


1214
01:08:21,760 --> 01:08:23,955
R/Z, just the reverse.

1215
01:08:23,955 --> 01:08:28,029


1216
01:08:28,029 --> 01:08:36,200
Now the expected
value of R/Z here

1217
01:08:36,200 --> 01:08:39,260
is 2 plus 1/2 divided
by 2 is 1 and 1/4.

1218
01:08:39,260 --> 01:08:42,810


1219
01:08:42,810 --> 01:08:44,359
And what's the
expected value of Z/R?

1220
01:08:44,359 --> 01:08:49,399


1221
01:08:49,399 --> 01:08:50,859
The average of
these is 1 and 1/4,

1222
01:08:50,859 --> 01:08:53,470
what's the average of these?

1223
01:08:53,470 --> 01:08:54,410
Same thing, 1 and 1/4.

1224
01:08:54,410 --> 01:08:58,020


1225
01:08:58,020 --> 01:09:00,830
So never, ever take
averages of ratios

1226
01:09:00,830 --> 01:09:02,689
without really knowing
what you're doing.

1227
01:09:02,689 --> 01:09:05,560


1228
01:09:05,560 --> 01:09:07,470
Any questions?

1229
01:09:07,470 --> 01:09:09,960
Yeah.

1230
01:09:09,960 --> 01:09:12,640
AUDIENCE: What would be the
word explanation of the expected

1231
01:09:12,640 --> 01:09:14,240
value of Z/R?

1232
01:09:14,240 --> 01:09:15,430
What is that?

1233
01:09:15,430 --> 01:09:18,270
PROFESSOR: That is the
average of the ratio.

1234
01:09:18,270 --> 01:09:21,270


1235
01:09:21,270 --> 01:09:25,859
It is not the ratio
of the average.

1236
01:09:25,859 --> 01:09:27,744
They are very different things.

1237
01:09:27,744 --> 01:09:29,660
And you can see how you
get caught up in that.

1238
01:09:29,660 --> 01:09:31,060
You could see how you have
linearity of expectation,

1239
01:09:31,060 --> 01:09:33,010
you got the product
rule for expectation.

1240
01:09:33,010 --> 01:09:39,135
You do not have a rule that
says this implies that.

1241
01:09:39,135 --> 01:09:41,590
AUDIENCE: [INAUDIBLE]

1242
01:09:41,590 --> 01:09:42,465
PROFESSOR: Which two?

1243
01:09:42,465 --> 01:09:46,710
AUDIENCE: [INAUDIBLE] Z/R?

1244
01:09:46,710 --> 01:09:48,910
PROFESSOR: Well, in
this case, they're one.

1245
01:09:48,910 --> 01:09:50,968
I don't think that'll
be true in general.

1246
01:09:50,968 --> 01:09:53,990
AUDIENCE: Does that
give you information?

1247
01:09:53,990 --> 01:09:55,820
PROFESSOR: They give
you information.

1248
01:09:55,820 --> 01:10:00,020
That may not be the
information you want.

1249
01:10:00,020 --> 01:10:01,530
It wouldn't imply
that which is what

1250
01:10:01,530 --> 01:10:04,220
you're after in some sense.

1251
01:10:04,220 --> 01:10:06,140
But it gives you
some information.

1252
01:10:06,140 --> 01:10:08,170
It's the expected average ratio.

1253
01:10:08,170 --> 01:10:12,700
The problem is the human brain
goes right from there to here.

1254
01:10:12,700 --> 01:10:14,450
It's just you do.

1255
01:10:14,450 --> 01:10:17,400
It's hard to help
yourself from doing it.

1256
01:10:17,400 --> 01:10:20,510
And it's not true.

1257
01:10:20,510 --> 01:10:23,430
That's the problem.

1258
01:10:23,430 --> 01:10:26,170
We have a version of this in the
one in the homework questions

1259
01:10:26,170 --> 01:10:27,420
which is true.

1260
01:10:27,420 --> 01:10:29,490
But it's a special
version of it where

1261
01:10:29,490 --> 01:10:33,030
you can say something positive.

1262
01:10:33,030 --> 01:10:36,020
Any questions about this?

1263
01:10:36,020 --> 01:10:39,180
So anybody ever shows
you an average of ratios,

1264
01:10:39,180 --> 01:10:42,120
you want the light to go
off and say, danger, danger.

1265
01:10:42,120 --> 01:10:44,682
Think what's happening here.

1266
01:10:44,682 --> 01:10:47,015
Or if you're ever analyzing
data to compare two systems.

1267
01:10:47,015 --> 01:10:52,880


1268
01:10:52,880 --> 01:10:55,540
So we talked a lot
about expectation, seen

1269
01:10:55,540 --> 01:10:56,840
a lot of ways of computing it.

1270
01:10:56,840 --> 01:10:59,310
We've done a lot of examples.

1271
01:10:59,310 --> 01:11:01,420
For the rest of today
and for next time,

1272
01:11:01,420 --> 01:11:04,180
we're going to talk
about deviations

1273
01:11:04,180 --> 01:11:06,870
from the expected value.

1274
01:11:06,870 --> 01:11:09,830
Now for some random
variables, they

1275
01:11:09,830 --> 01:11:11,880
are very likely to
take on values that

1276
01:11:11,880 --> 01:11:13,850
are near their expectation.

1277
01:11:13,850 --> 01:11:17,510
For example, if
I flip 100 coins.

1278
01:11:17,510 --> 01:11:20,770
And say they're fair and
mutually independent.

1279
01:11:20,770 --> 01:11:24,389
We know that the expected
number of heads is 50.

1280
01:11:24,389 --> 01:11:25,930
Does anybody remember
the probability

1281
01:11:25,930 --> 01:11:30,990
of getting far from that, namely
having 25 or fewer heads or 75

1282
01:11:30,990 --> 01:11:32,564
or more heads?

1283
01:11:32,564 --> 01:11:33,480
Remember, we did that?

1284
01:11:33,480 --> 01:11:35,760
It was a couple of weeks ago?

1285
01:11:35,760 --> 01:11:39,334
Is it likely to have
25 or fewer heads?

1286
01:11:39,334 --> 01:11:41,000
AUDIENCE: It's less
than 1 in a million?

1287
01:11:41,000 --> 01:11:42,140
PROFESSOR: Less
than 1 in a million.

1288
01:11:42,140 --> 01:11:42,400
Yeah.

1289
01:11:42,400 --> 01:11:43,450
It was 1 in 5
million or something.

1290
01:11:43,450 --> 01:11:45,420
I don't know, some
horribly small number.

1291
01:11:45,420 --> 01:11:49,510
So if I flip 100 coins,
I expect to get 50 heads.

1292
01:11:49,510 --> 01:11:52,480
And I'm very likely to
get close to 50 heads.

1293
01:11:52,480 --> 01:11:56,080
I'm not going to be 25 off.

1294
01:11:56,080 --> 01:11:59,240
And then the example
we had in recitation,

1295
01:11:59,240 --> 01:12:02,350
you got a noisy
channel, and you expect

1296
01:12:02,350 --> 01:12:06,640
an error rate, 1% of your
10,000 bits to be corrupted.

1297
01:12:06,640 --> 01:12:08,830
The chance of
getting 2% corrupted

1298
01:12:08,830 --> 01:12:12,210
was like-- what was it, 2 to
the minus 60 or something?

1299
01:12:12,210 --> 01:12:17,710
Extremely unlikely to be
far from the expected value.

1300
01:12:17,710 --> 01:12:21,900
But there's other cases where
you are likely-- you could well

1301
01:12:21,900 --> 01:12:24,189
be far from the expected value.

1302
01:12:24,189 --> 01:12:25,730
Can anybody remember
an example we've

1303
01:12:25,730 --> 01:12:32,510
done where you are almost
surely way off your expected

1304
01:12:32,510 --> 01:12:35,700
value for a random variable?

1305
01:12:35,700 --> 01:12:39,730
Anybody remember an example
we did that has that feature?

1306
01:12:39,730 --> 01:12:41,239
AUDIENCE: The appetizer I think.

1307
01:12:41,239 --> 01:12:42,280
PROFESSOR: The appetizer.

1308
01:12:42,280 --> 01:12:43,460
Let's see.

1309
01:12:43,460 --> 01:12:49,350
Appetizers, you expect 1, but
you're almost certain to be 0.

1310
01:12:49,350 --> 01:12:51,290
Or actually, you're
almost certain to be 0,

1311
01:12:51,290 --> 01:12:53,560
and you have a
chance of being n.

1312
01:12:53,560 --> 01:12:55,204
So if you count 0
as being close to 1,

1313
01:12:55,204 --> 01:12:57,120
you're likely to be close
to your expectation.

1314
01:12:57,120 --> 01:13:01,690
Because you're likely to
be 0, and you expect 1.

1315
01:13:01,690 --> 01:13:04,851
Remember that noisy
channel problem--

1316
01:13:04,851 --> 01:13:06,600
not the noisy channel,
the latency problem

1317
01:13:06,600 --> 01:13:08,330
across the channel?

1318
01:13:08,330 --> 01:13:12,310
And we show that the expected
latency was infinite?

1319
01:13:12,310 --> 01:13:15,580
But 99% of the time you
had 10 milliseconds,

1320
01:13:15,580 --> 01:13:17,770
something like that?

1321
01:13:17,770 --> 01:13:20,020
There's an example where
almost all the time you

1322
01:13:20,020 --> 01:13:22,870
are far from your expectation
which is infinite.

1323
01:13:22,870 --> 01:13:25,380
So there are examples
that go both ways.

1324
01:13:25,380 --> 01:13:28,250


1325
01:13:28,250 --> 01:13:33,570
Now let's look at another
couple of examples

1326
01:13:33,570 --> 01:13:36,700
that'll motivate the
definition that measures this.

1327
01:13:36,700 --> 01:13:41,160


1328
01:13:41,160 --> 01:13:45,930
I'd say that we've got a simple
Bernoulli random variable where

1329
01:13:45,930 --> 01:13:51,250
the probability that
R is 1,000 is 1/2,

1330
01:13:51,250 --> 01:13:58,660
and the probability that
R is minus 1,000 is 1/2.

1331
01:13:58,660 --> 01:14:00,660
Then the expected
value of R is 0.

1332
01:14:00,660 --> 01:14:05,440


1333
01:14:05,440 --> 01:14:07,770
Similarly, we could
have another one, S,

1334
01:14:07,770 --> 01:14:12,540
where the probability
that S equals 1 is 1/2,

1335
01:14:12,540 --> 01:14:16,230
and the probability that
S equals minus 1 is 1/2.

1336
01:14:16,230 --> 01:14:18,110
And the expected
value of S is 0.

1337
01:14:18,110 --> 01:14:20,820


1338
01:14:20,820 --> 01:14:23,240
Now if this was a
betting game and we're

1339
01:14:23,240 --> 01:14:26,470
talking about dollars--
here's where you're

1340
01:14:26,470 --> 01:14:28,910
wagering $1,000, fair game.

1341
01:14:28,910 --> 01:14:31,550
Here's where you're wagering $1.

1342
01:14:31,550 --> 01:14:36,950
Now in this game--
both games are fair.

1343
01:14:36,950 --> 01:14:38,980
Expected value is 0.

1344
01:14:38,980 --> 01:14:43,070
But here you're likely to end
up near your expected value.

1345
01:14:43,070 --> 01:14:46,130
Here you're certain to be far by
some measure from your expected

1346
01:14:46,130 --> 01:14:47,290
value.

1347
01:14:47,290 --> 01:14:52,740
And in fact, if you were
offered to play a game,

1348
01:14:52,740 --> 01:14:56,270
you might have a real decision
as to which game you played.

1349
01:14:56,270 --> 01:15:00,990
If you like risk, you
might play that game.

1350
01:15:00,990 --> 01:15:05,000
If you're risk averse, maybe
you stick with this game

1351
01:15:05,000 --> 01:15:07,180
because what you could
lose would be less.

1352
01:15:07,180 --> 01:15:10,460


1353
01:15:10,460 --> 01:15:16,770
Now this motivates the
definition of the variance

1354
01:15:16,770 --> 01:15:20,700
because it helps mathematicians
distinguish between these two

1355
01:15:20,700 --> 01:15:22,398
cases with a simple statistic.

1356
01:15:22,398 --> 01:15:33,530


1357
01:15:33,530 --> 01:15:44,670
The variance of a
random variable R--

1358
01:15:44,670 --> 01:15:49,170
we'll denote it by
var, V-A-R, of R--

1359
01:15:49,170 --> 01:15:54,210
is defined as the expected
value of the random variable

1360
01:15:54,210 --> 01:16:01,250
minus this expected
value squared.

1361
01:16:01,250 --> 01:16:02,950
That's sort of a mouthful there.

1362
01:16:02,950 --> 01:16:04,075
So let's break it down.

1363
01:16:04,075 --> 01:16:07,285


1364
01:16:07,285 --> 01:16:11,240
This is the expected value
of R. This is the deviation

1365
01:16:11,240 --> 01:16:14,130
from the expected value.

1366
01:16:14,130 --> 01:16:16,630
So this is the
deviation from the mean.

1367
01:16:16,630 --> 01:16:21,490


1368
01:16:21,490 --> 01:16:22,770
Then we square it.

1369
01:16:22,770 --> 01:16:25,590


1370
01:16:25,590 --> 01:16:31,800
So that equals the
square of the deviation.

1371
01:16:31,800 --> 01:16:36,810
And then we take the
expected value of the square.

1372
01:16:36,810 --> 01:16:42,190
So the variance equals
the expected value

1373
01:16:42,190 --> 01:16:46,156
of the square of the deviation.

1374
01:16:46,156 --> 01:16:50,829


1375
01:16:50,829 --> 01:16:52,370
In other words, the
variance gives us

1376
01:16:52,370 --> 01:16:55,630
the average of the
squares of the amount

1377
01:16:55,630 --> 01:16:59,662
by which the random variable
deviates from its mean.

1378
01:16:59,662 --> 01:17:04,500
Now the idea behind this is
that if a random variable is

1379
01:17:04,500 --> 01:17:08,710
likely to deviate from its
mean, the variance will be high.

1380
01:17:08,710 --> 01:17:10,580
And if it's likely
to be near its mean,

1381
01:17:10,580 --> 01:17:12,180
the variance will be low.

1382
01:17:12,180 --> 01:17:15,805
And so variance can tell us
something about the expected

1383
01:17:15,805 --> 01:17:16,305
deviation.

1384
01:17:16,305 --> 01:17:23,920


1385
01:17:23,920 --> 01:17:26,835
So let's compute the
variance for R and S

1386
01:17:26,835 --> 01:17:29,220
and see what happens.

1387
01:17:29,220 --> 01:17:35,010
So with R minus the
expected value of R, well,

1388
01:17:35,010 --> 01:17:37,670
that is going to be
1,000, because you expect

1389
01:17:37,670 --> 01:17:42,420
the value of 0, with
probability 1/2, and minus 1,000

1390
01:17:42,420 --> 01:17:44,770
with probability 1/2.

1391
01:17:44,770 --> 01:17:45,825
Then I square that.

1392
01:17:45,825 --> 01:17:51,220


1393
01:17:51,220 --> 01:17:58,430
Well, I square 1,000, I get a
million with probability 1/2.

1394
01:17:58,430 --> 01:18:00,700
And I square minus
1,000, I get a million

1395
01:18:00,700 --> 01:18:05,340
again with probability 1/2.

1396
01:18:05,340 --> 01:18:09,620
And so therefore,
the variance of R,

1397
01:18:09,620 --> 01:18:12,664
well, it's the expected value
of this, which is-- well,

1398
01:18:12,664 --> 01:18:13,580
it's always a million.

1399
01:18:13,580 --> 01:18:14,610
So it's just a million.

1400
01:18:14,610 --> 01:18:18,650


1401
01:18:18,650 --> 01:18:20,160
Big.

1402
01:18:20,160 --> 01:18:26,140
Now if I were to do this with S,
S minus the expected value of S

1403
01:18:26,140 --> 01:18:31,170
is 1 with probability 1/2,
minus 1 with probability 1/2.

1404
01:18:31,170 --> 01:18:39,290
If I square that, well,
I get 1 squared is 1,

1405
01:18:39,290 --> 01:18:42,670
minus 1 squared is 1.

1406
01:18:42,670 --> 01:18:47,280
And so the variance of S is
the expected value of this.

1407
01:18:47,280 --> 01:18:50,010
And that's just 1.

1408
01:18:50,010 --> 01:18:52,590
So a big difference
in the variance.

1409
01:18:52,590 --> 01:18:55,520
So the variance being different
tells us these random variables

1410
01:18:55,520 --> 01:18:58,110
are-- the distributions
are very different even

1411
01:18:58,110 --> 01:19:01,220
though their expected
values are the same.

1412
01:19:01,220 --> 01:19:02,870
And the guy with
big variance says,

1413
01:19:02,870 --> 01:19:06,920
hey, we're likely to
deviate from the mean here.

1414
01:19:06,920 --> 01:19:09,720
And so risk averse people
stay away from strategies

1415
01:19:09,720 --> 01:19:11,678
when they're investing
that have high variance.

1416
01:19:11,678 --> 01:19:18,370


1417
01:19:18,370 --> 01:19:24,710
Now does anybody have any idea
why we square the deviation?

1418
01:19:24,710 --> 01:19:26,850
Why don't we just-- why
didn't mathematicians

1419
01:19:26,850 --> 01:19:28,890
when they figured out
this stuff I don't know

1420
01:19:28,890 --> 01:19:30,931
how many centuries ago,
why didn't they just take

1421
01:19:30,931 --> 01:19:32,930
the expected deviation?

1422
01:19:32,930 --> 01:19:34,510
Why do the stupid
squaring thing?

1423
01:19:34,510 --> 01:19:37,110
That only is going
to complicate it?

1424
01:19:37,110 --> 01:19:44,250
Why don't we instead
compute the expected value

1425
01:19:44,250 --> 01:19:48,730
of R minus the mean?

1426
01:19:48,730 --> 01:19:51,620
Why didn't they do that
and call that the variance?

1427
01:19:51,620 --> 01:19:53,170
Yeah?

1428
01:19:53,170 --> 01:19:54,252
That's zero.

1429
01:19:54,252 --> 01:19:55,490
Yeah.

1430
01:19:55,490 --> 01:19:57,210
Because by linearity
of expectation,

1431
01:19:57,210 --> 01:19:59,670
that corollary
[? 4-2 ?] or whatever,

1432
01:19:59,670 --> 01:20:03,590
this is just the expected value
of R minus the expected value

1433
01:20:03,590 --> 01:20:09,030
of the expected value of R. The
expected value of a scalar is

1434
01:20:09,030 --> 01:20:09,925
just that scalar.

1435
01:20:09,925 --> 01:20:13,400


1436
01:20:13,400 --> 01:20:17,270
And that is 0.

1437
01:20:17,270 --> 01:20:20,570
So the expected
deviation from the mean

1438
01:20:20,570 --> 01:20:24,042
is 0 because of how
the mean is defined.

1439
01:20:24,042 --> 01:20:25,750
It's the midpoint,
the weighted midpoint.

1440
01:20:25,750 --> 01:20:28,320
The times you're high
cancel out the times you're

1441
01:20:28,320 --> 01:20:31,950
low if you got the mean right.

1442
01:20:31,950 --> 01:20:33,820
And so this is a
useless definition.

1443
01:20:33,820 --> 01:20:36,150
It's always 0.

1444
01:20:36,150 --> 01:20:40,262
So mathematicians had to do
something to capture this.

1445
01:20:40,262 --> 01:20:42,220
Now what would have been
the more logical thing

1446
01:20:42,220 --> 01:20:43,390
to do that is the next step.

1447
01:20:43,390 --> 01:20:44,910
This doesn't work,
but what would

1448
01:20:44,910 --> 01:20:47,730
you think the mathematicians
would've done?

1449
01:20:47,730 --> 01:20:51,670
Absolute value would have
made a lot of sense here.

1450
01:20:51,670 --> 01:20:54,370
Why they didn't do that?

1451
01:20:54,370 --> 01:20:56,440
Well, you could
do that, but it's

1452
01:20:56,440 --> 01:20:57,960
hard to work with
mathematically.

1453
01:20:57,960 --> 01:21:01,470
You can't prove nice
theorems, it turns out.

1454
01:21:01,470 --> 01:21:05,050
If you put the square in there
and make that be the variance,

1455
01:21:05,050 --> 01:21:09,030
you can prove a theorem
about linearity of variance.

1456
01:21:09,030 --> 01:21:11,290
And if the random
variables are independent,

1457
01:21:11,290 --> 01:21:14,090
then the variance of the sum
is the sum of the variances.

1458
01:21:14,090 --> 01:21:16,630
And mathematicians like
that kind of thing.

1459
01:21:16,630 --> 01:21:19,640
It makes it easier to work
with and do things with.

1460
01:21:19,640 --> 01:21:23,320
Now there are also other
choices like, in fact,

1461
01:21:23,320 --> 01:21:26,120
there's a special name
for a weird case where

1462
01:21:26,120 --> 01:21:27,685
you take the fourth power.

1463
01:21:27,685 --> 01:21:32,450


1464
01:21:32,450 --> 01:21:33,360
You could do that.

1465
01:21:33,360 --> 01:21:35,690
As long as an even
power, you could do it.

1466
01:21:35,690 --> 01:21:39,040
And that's actually
called the kurtosis.

1467
01:21:39,040 --> 01:21:41,260
Sounds like a foot disease.

1468
01:21:41,260 --> 01:21:44,370
But it's the kurtosis
of the random variable.

1469
01:21:44,370 --> 01:21:46,915
Now we're not going to worry
about that in this class.

1470
01:21:46,915 --> 01:21:50,030
But we are going to
worry about variance.

1471
01:21:50,030 --> 01:21:52,350
And let me do one
more definition,

1472
01:21:52,350 --> 01:21:56,560
then we'll talk about
variance a lot more tomorrow.

1473
01:21:56,560 --> 01:21:58,480
That square is a bit of a pain.

1474
01:21:58,480 --> 01:22:02,310
And to get rid of it, they
made another definition

1475
01:22:02,310 --> 01:22:06,590
after the fact called
the standard deviation.

1476
01:22:06,590 --> 01:22:10,790
And standard deviation
is defined as follows.

1477
01:22:10,790 --> 01:22:13,790


1478
01:22:13,790 --> 01:22:29,650
For a random variable R,
the standard deviation of R

1479
01:22:29,650 --> 01:22:34,810
is denoted by a sigma
of R. And it's just

1480
01:22:34,810 --> 01:22:38,750
the square root of
the variance, undoing

1481
01:22:38,750 --> 01:22:41,650
that nasty square
root after the fact.

1482
01:22:41,650 --> 01:22:45,250
So it turns out to be the
square root of the expectation

1483
01:22:45,250 --> 01:22:48,940
of the deviation squared.

1484
01:22:48,940 --> 01:22:52,090
Another name for this
you've probably seen,

1485
01:22:52,090 --> 01:23:02,770
it's the root of the mean of
the square of the deviations.

1486
01:23:02,770 --> 01:23:05,532
And so you get this thing
called root-mean-square,

1487
01:23:05,532 --> 01:23:06,990
which if any of
you ever done curve

1488
01:23:06,990 --> 01:23:08,614
fitting or any of
those kinds of things

1489
01:23:08,614 --> 01:23:12,152
in statistics or whatever, this
is what you're talking about.

1490
01:23:12,152 --> 01:23:14,360
And so that's why that
expression were to come about.

1491
01:23:14,360 --> 01:23:18,090


1492
01:23:18,090 --> 01:23:20,780
So for the standard
deviation of R--

1493
01:23:20,780 --> 01:23:23,670
what's the standard
deviation of R?

1494
01:23:23,670 --> 01:23:24,597
1,000?

1495
01:23:24,597 --> 01:23:26,180
In effect, that's
pretty close to what

1496
01:23:26,180 --> 01:23:28,360
you expect the deviation to be.

1497
01:23:28,360 --> 01:23:30,095
What's the standard
deviation of S?

1498
01:23:30,095 --> 01:23:32,950


1499
01:23:32,950 --> 01:23:33,450
1.

1500
01:23:33,450 --> 01:23:34,825
Square root of 1
is 1, and that's

1501
01:23:34,825 --> 01:23:37,240
what you expect its
deviation to be.

1502
01:23:37,240 --> 01:23:40,210
So we'll do more of this
tomorrow on recitation.

1503
01:23:40,210 --> 01:23:43,357